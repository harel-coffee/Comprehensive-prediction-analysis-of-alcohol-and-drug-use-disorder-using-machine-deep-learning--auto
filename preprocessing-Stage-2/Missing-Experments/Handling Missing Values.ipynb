{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broken-berkeley",
   "metadata": {},
   "source": [
    "## Missing data methods for our dataset \n",
    "The impact of missing data on quantitative research can be serious, leading to biased estimates of parameters, loss of information, decreased statistical power, increased standard errors, and weakened generalizability of findings. Firstly, understand that there is NO good way to deal with missing data. We have come across different solutions for data imputation depending on the kind of problem —Analysis, ML, Regression, etc. and it is difficult to provide a general solution. Here, we attempting to summarize the most commonly used methods and trying to find a structural solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-topic",
   "metadata": {},
   "source": [
    "### read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "magnetic-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunset-roommate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 11:50:51.010422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:\n",
      "2021-08-12 11:50:51.010438: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DAST', 'SEX', 'HISPANIC', 'RACE', 'VET', 'ACTIVE', 'DEPLOY', 'AUDIT',\n",
      "       'COSCREEN', 'BI', 'BT', 'RT', 'ANYALC', 'BINGEDAYS', 'DRUGDAYS',\n",
      "       'ALCDRUGS', 'DAYSCOCAINE', 'MARYJDAYS', 'METHDAYS', 'INJECT', 'AGE',\n",
      "       'TOBMONTH'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAST</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>AUDIT</th>\n",
       "      <th>COSCREEN</th>\n",
       "      <th>BI</th>\n",
       "      <th>...</th>\n",
       "      <th>ANYALC</th>\n",
       "      <th>BINGEDAYS</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>DAYSCOCAINE</th>\n",
       "      <th>MARYJDAYS</th>\n",
       "      <th>METHDAYS</th>\n",
       "      <th>INJECT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DAST  SEX  HISPANIC  RACE  VET  ACTIVE  DEPLOY  AUDIT  COSCREEN   BI  \\\n",
       "2059   0.0  0.0       0.0   2.0  1.0     0.0     0.0    1.0       0.0  0.0   \n",
       "6175   0.0  1.0       0.0   2.0  0.0     0.0     0.0    0.0       0.0  0.0   \n",
       "4517   0.0  1.0       0.0   2.0  0.0     0.0     0.0    0.0       0.0  0.0   \n",
       "6680   0.0  0.0       0.0   2.0  NaN     NaN     NaN    0.0       0.0  0.0   \n",
       "3376   0.0  1.0       0.0   1.0  0.0     0.0     0.0    0.0       0.0  0.0   \n",
       "\n",
       "      ...  ANYALC  BINGEDAYS  DRUGDAYS  ALCDRUGS  DAYSCOCAINE  MARYJDAYS  \\\n",
       "2059  ...     NaN        NaN       0.0       NaN          0.0        0.0   \n",
       "6175  ...     1.0        0.0       0.0       0.0          0.0        0.0   \n",
       "4517  ...     0.0        0.0       0.0       0.0          0.0        0.0   \n",
       "6680  ...     NaN        NaN       NaN       NaN          NaN        NaN   \n",
       "3376  ...     0.0        0.0       0.0       0.0          0.0        0.0   \n",
       "\n",
       "      METHDAYS  INJECT   AGE  TOBMONTH  \n",
       "2059       0.0     0.0  55.0       0.0  \n",
       "6175       0.0     0.0  20.0       0.0  \n",
       "4517       0.0     0.0  46.0       0.0  \n",
       "6680       NaN     NaN  73.0       NaN  \n",
       "3376       0.0     0.0  19.0       0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "data_0 = pd.read_csv('final2.csv')\n",
    "data_0 = data_0.iloc[: , 1:]\n",
    "data_0=data_0.drop(['BIRTH','SCREEN','HALLUC','ANYOPIATEDAYS', 'METHADONE','OTHERDRUGS'],axis=1)\n",
    "data_0=data_0.sample(frac=1)\n",
    "print (data_0.columns.str.strip())\n",
    "data_0.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit=np.where( (data_0['AUDIT']==0) & (data_0['ANYALC'].isnull()))[0]\n",
    "len(audit)\n",
    "for i in audit: \n",
    "    data_0.iloc[i,12]=0\n",
    "data_0.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-terrorism",
   "metadata": {},
   "source": [
    "#### The msno.matrix nullity matrix is a data-dense display which lets you quickly visually pick out patterns in data completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "msno.matrix(data_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-alfred",
   "metadata": {},
   "source": [
    "#### The missingno correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(data_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-cooper",
   "metadata": {},
   "source": [
    "### The dendrogram allows you to more fully correlate variable completion, revealing trends deeper than the pairwise ones visible in the correlation heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-scholarship",
   "metadata": {},
   "source": [
    " ### 1) Dropping the rows that have null Values.\n",
    "Listwise deletion (complete-case analysis) removes all data for an observation that has one or more missing values.\n",
    "#### Advantages:\n",
    "    Quick Process and Simpler\n",
    "\n",
    "#### Disadvantages:\n",
    "    Significant loss of data (~40 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-departure",
   "metadata": {},
   "source": [
    "### 2)  Replace Missing Values with Mean, Median & Mode & Standard Deviation & Minimum & Maximum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DAST'] = df['DAST'].astype(\"category\")\n",
    "df['SEX'] = df['SEX'].astype(\"category\")\n",
    "df['HISPANIC'] = df['HISPANIC'].astype(\"category\")\n",
    "df['RACE'] = df['RACE'].astype(\"category\")\n",
    "df['VET'] = df['VET'].astype(bool)\n",
    "df['ACTIVE'] = df['ACTIVE'].astype(bool)\n",
    "df['DEPLOY'] = df['DEPLOY'].astype(\"category\")\n",
    "df['AUDIT'] = df['AUDIT'].astype(\"category\")\n",
    "df['COSCREEN'] = df['COSCREEN'].astype(bool)\n",
    "df['RT'] = df['RT'].astype(\"category\")\n",
    "df['BI'] = df['BI'].astype(bool)\n",
    "df['BT'] = df['BT'].astype(bool)\n",
    "df['INJECT'] = df['INJECT'].astype(bool)\n",
    "df['TOBMONTH'] = df['TOBMONTH'].astype(bool)\n",
    "###############################################################\n",
    "df['ANYALC'] = df['ANYALC'].astype(float)\n",
    "df['BINGEDAYS'] = df['BINGEDAYS'].astype(float)\n",
    "df['DRUGDAYS'] = df['DRUGDAYS'].astype(float)\n",
    "df['ALCDRUGS'] = df['ALCDRUGS'].astype(float)\n",
    "df['DAYSCOCAINE'] = df['DAYSCOCAINE'].astype(float)\n",
    "df['MARYJDAYS'] = df['MARYJDAYS'].astype(float)\n",
    "df['ANYOPIATEDAYS'] = df['ANYOPIATEDAYS'].astype(float)\n",
    "df['METHADONE'] = df['METHADONE'].astype(float)\n",
    "df['HALLUC'] = df['HALLUC'].astype(float)\n",
    "df['METHDAYS'] = df['METHDAYS'].astype(float)\n",
    "df['OTHERDRUGS'] =df['OTHERDRUGS'].astype(float)\n",
    "df['AGE'] = df['AGE'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-homeless",
   "metadata": {},
   "source": [
    "### For Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing missing values mod (catogrey)\n",
    "df['DAST'] = df['DAST'].fillna(df['DAST'].mode())\n",
    "df['SEX'] = df['SEX'].fillna(df['SEX'].mode())\n",
    "df['HISPANIC'] = df['HISPANIC'].fillna(df['HISPANIC'].mode())\n",
    "df['RACE'] = df['RACE'].fillna(df['RACE'].mode())\n",
    "df['VET'] = df['VET'].fillna(df['VET'].mode())\n",
    "df['ACTIVE'] = df['ACTIVE'].fillna(df['ACTIVE'].mode())\n",
    "df['DEPLOY'] = df['DEPLOY'].fillna(df['DEPLOY'].mode())\n",
    "df['AUDIT'] = df['AUDIT'].fillna(df['AUDIT'].mode())\n",
    "df['COSCREEN'] = df['COSCREEN'].fillna(df['COSCREEN'].mode())\n",
    "df['RT'] = df['RT'].fillna(df['RT'].mode())\n",
    "df['BI'] = df['BI'].fillna(df['BI'].mode())\n",
    "df['BT'] = df['BT'].fillna(df['BT'].mode())\n",
    "df['INJECT'] = df['INJECT'].fillna(df['INJECT'].mode())\n",
    "df['TOBMONTH'] = df['TOBMONTH'].fillna(df['TOBMONTH'].mode())\n",
    "\n",
    "###############################################################\n",
    "\n",
    "# replacing missing values in quantity (float) median \n",
    "df['ANYALC'] = df['ANYALC'].fillna(df['ANYALC'].median())\n",
    "df['BINGEDAYS'] = df['BINGEDAYS'].fillna(df['BINGEDAYS'].median())\n",
    "df['DRUGDAYS'] = df['DRUGDAYS'].fillna(df['DRUGDAYS'].median())\n",
    "df['ALCDRUGS'] = df['ALCDRUGS'].fillna(df['ALCDRUGS'].median())\n",
    "df['DAYSCOCAINE'] = df['DAYSCOCAINE'].fillna(df['DAYSCOCAINE'].median())\n",
    "df['MARYJDAYS'] = df['MARYJDAYS'].fillna(df['MARYJDAYS'].median())\n",
    "df['ANYOPIATEDAYS'] = df['ANYOPIATEDAYS'].fillna(df['ANYOPIATEDAYS'].median())\n",
    "df['METHADONE'] = df['METHADONE'].fillna(df['METHADONE'].median())\n",
    "df['HALLUC'] = df['HALLUC'].fillna(df['HALLUC'].median())\n",
    "df['METHDAYS'] = df['METHDAYS'].fillna(df['METHDAYS'].median())\n",
    "df['OTHERDRUGS'] = df['OTHERDRUGS'].fillna(df['OTHERDRUGS'].median())\n",
    "df['AGE'] = df['AGE'].fillna(df['AGE'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-detection",
   "metadata": {},
   "source": [
    "### 3) DataWig \n",
    "DataWig learns Machine Learning models to impute missing values in tables (paper: DataWig Missing Value Imputation for Tables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-timing",
   "metadata": {},
   "source": [
    "### case (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data_0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df2.copy()\n",
    "df1=df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['DAST'] = df2['DAST'].astype(str)\n",
    "df2['SEX'] = df2['SEX'].astype(str)\n",
    "df2['HISPANIC'] = df2['HISPANIC'].astype(str)\n",
    "df2['RACE'] = df2['RACE'].astype(str)\n",
    "df2['VET'] = df2['VET'].astype(str)\n",
    "df2['ACTIVE'] = df2['ACTIVE'].astype(str)\n",
    "df2['DEPLOY'] = df2['DEPLOY'].astype(str)\n",
    "df2['AUDIT'] = df2['AUDIT'].astype(str)\n",
    "df2['COSCREEN'] = df2['COSCREEN'].astype(str)\n",
    "df2['RT'] = df2['RT'].astype(str)\n",
    "df2['BI'] = df2['BI'].astype(str)\n",
    "df2['BT'] = df2['BT'].astype(str)\n",
    "df2['INJECT'] = df2['INJECT'].astype(str)\n",
    "df2['TOBMONTH'] = df2['TOBMONTH'].astype(str)\n",
    "###############################################################\n",
    "df2['ANYALC'] = df2['ANYALC'].astype(float)\n",
    "df2['BINGEDAYS'] = df2['BINGEDAYS'].astype(float)\n",
    "df2['DRUGDAYS'] = df2['DRUGDAYS'].astype(float)\n",
    "\n",
    "df2['ALCDRUGS'] = df2['ALCDRUGS'].astype(float)\n",
    "df2['DAYSCOCAINE'] = df2['DAYSCOCAINE'].astype(float)\n",
    "df2['MARYJDAYS'] = df2['MARYJDAYS'].astype(float)\n",
    "\n",
    "df2['ANYOPIATEDAYS'] = df2['ANYOPIATEDAYS'].astype(float)\n",
    "df2['METHADONE'] = df2['METHADONE'].astype(float)\n",
    "df2['HALLUC'] = df2['HALLUC'].astype(float)\n",
    "\n",
    "df2['METHDAYS'] = df2['METHDAYS'].astype(float)\n",
    "df2['OTHERDRUGS'] =df2['OTHERDRUGS'].astype(float)\n",
    "df2['AGE'] = df2['AGE'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['DAST'] = df1['DAST'].astype(str)\n",
    "df1['SEX'] = df1['SEX'].astype(str)\n",
    "df1['HISPANIC'] = df1['HISPANIC'].astype(str)\n",
    "df1['RACE'] = df1['RACE'].astype(str)\n",
    "df1['VET'] = df1['VET'].astype(str)\n",
    "df1['ACTIVE'] = df1['ACTIVE'].astype(str)\n",
    "df1['DEPLOY'] = df1['DEPLOY'].astype(str)\n",
    "df1['AUDIT'] = df1['AUDIT'].astype(str)\n",
    "df1['COSCREEN'] = df1['COSCREEN'].astype(str)\n",
    "df1['RT'] = df1['RT'].astype(str)\n",
    "df1['BI'] = df1['BI'].astype(str)\n",
    "df1['BT'] = df1['BT'].astype(str)\n",
    "df1['INJECT'] = df1['INJECT'].astype(str)\n",
    "df1['TOBMONTH'] = df1['TOBMONTH'].astype(str)\n",
    "###############################################################\n",
    "df1['ANYALC'] = df1['ANYALC'].astype(float)\n",
    "df1['BINGEDAYS'] = df1['BINGEDAYS'].astype(float)\n",
    "df1['DRUGDAYS'] = df1['DRUGDAYS'].astype(float)\n",
    "\n",
    "df1['ALCDRUGS'] = df1['ALCDRUGS'].astype(float)\n",
    "df1['DAYSCOCAINE'] = df1['DAYSCOCAINE'].astype(float)\n",
    "df1['MARYJDAYS'] = df1['MARYJDAYS'].astype(float)\n",
    "\n",
    "df1['ANYOPIATEDAYS'] = df1['ANYOPIATEDAYS'].astype(float)\n",
    "df1['METHADONE'] = df1['METHADONE'].astype(float)\n",
    "df1['HALLUC'] = df1['HALLUC'].astype(float)\n",
    "\n",
    "df1['METHDAYS'] = df1['METHDAYS'].astype(float)\n",
    "df1['OTHERDRUGS'] =df1['OTHERDRUGS'].astype(float)\n",
    "df1['AGE'] = df1['AGE'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-regression",
   "metadata": {},
   "source": [
    "###  Imputation of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datawig\n",
    "import datawig\n",
    "df_train, df_test = datawig.utils.random_split(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-camping",
   "metadata": {},
   "source": [
    "### DAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['RT','BI','DRUGDAYS','COSCREEN','MARYJDAYS','BT','ALCDRUGS','AUDIT','TOBMONTH','ANYALC'], # column(s) containing information about the column we want to impute\n",
    "    output_column='DAST', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions  = imputer.predict(df_test)\n",
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score,accuracy_score\n",
    "print(\"Precision Score : \",precision_score(predictions['DAST'], predictions['DAST_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions['DAST'], predictions['DAST_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"accuracy Score : \",accuracy_score(predictions['DAST'], predictions['DAST_imputed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions  = imputer.predict(df2)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-payment",
   "metadata": {},
   "source": [
    "### SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig\n",
    "imputer1 = datawig.SimpleImputer(\n",
    "    input_columns=['VET','AGE','DEPLOY','RACE','HISPANIC','ALCDRUGS','AUDIT','ANYALC'], # column(s) containing information about the column we want to impute\n",
    "    output_column='SEX', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer1.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1  = imputer1.predict(df_test)\n",
    "predictions1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Precision Score : \",precision_score(predictions1['SEX'], predictions1['SEX_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions1['SEX'], predictions1['SEX_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"accuracy Score : \",accuracy_score(predictions1['SEX'], predictions1['SEX_imputed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1  = imputer1.predict(df2)\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-shipping",
   "metadata": {},
   "source": [
    "### HISPANIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer2 = datawig.SimpleImputer(\n",
    "    input_columns=['VET','AGE','DEPLOY','RACE','SEX','DRUGDAYS','TOBMONTH','DAST'], # column(s) containing information about the column we want to impute\n",
    "    output_column='HISPANIC', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer2.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2  = imputer2.predict(df_test)\n",
    "predictions2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions2['HISPANIC'], predictions2['HISPANIC_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions2['HISPANIC'], predictions2['HISPANIC_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"accuracy Score : \",accuracy_score(predictions2['HISPANIC'], predictions2['HISPANIC_imputed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2  = imputer2.predict(df2)\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-bristol",
   "metadata": {},
   "source": [
    "### RACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer3 = datawig.SimpleImputer(\n",
    "    input_columns=['HISPANIC','SEX','VET','AGE','TOBMONTH','DEPLOY','RT','DAST','MARYJDAYS'], # column(s) containing information about the column we want to impute\n",
    "    output_column='RACE', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer3.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3  = imputer3.predict(df_test)\n",
    "predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions3['RACE'], predictions3['RACE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions3['RACE'], predictions3['RACE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3  = imputer3.predict(df2)\n",
    "predictions3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-parcel",
   "metadata": {},
   "source": [
    "### VET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer4 = datawig.SimpleImputer(\n",
    "    input_columns=['DEPLOY','SEX','AGE','RACE','ACTIVE','HISPANIC','DAST'], # column(s) containing information about the column we want to impute\n",
    "    output_column='VET', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer4.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4  = imputer4.predict(df_test)\n",
    "predictions4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions4['VET'], predictions4['VET_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions4['VET'], predictions4['VET_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4  = imputer4.predict(df2)\n",
    "predictions4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-classics",
   "metadata": {},
   "source": [
    "### ACTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer5 = datawig.SimpleImputer(\n",
    "    input_columns=['VET','DEPLOY','AGE','BT','DAST','BINGEDAYS','SEX','DRUGDAYS','ANYALC','ALCDRUGS'], # column(s) containing information about the column we want to impute\n",
    "    output_column='ACTIVE', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer5.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions5  = imputer5.predict(df_test)\n",
    "predictions5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions5['ACTIVE'], predictions5['ACTIVE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions5['ACTIVE'], predictions5['ACTIVE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions5  = imputer5.predict(df2)\n",
    "predictions5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-anchor",
   "metadata": {},
   "source": [
    "### DEPLOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer6 = datawig.SimpleImputer(\n",
    "    input_columns=['VET','SEX','ACTIVE','AGE','RACE','ANYALC','HISPANIC','AUDIT','ALCDRUGS'], # column(s) containing information about the column we want to impute\n",
    "    output_column='DEPLOY', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer6.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions6  = imputer6.predict(df_test)\n",
    "predictions6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions6['DEPLOY'], predictions6['DEPLOY_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions6['DEPLOY'], predictions6['DEPLOY_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions6  = imputer6.predict(df2)\n",
    "predictions6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-prevention",
   "metadata": {},
   "source": [
    "### AUDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer7 = datawig.SimpleImputer(\n",
    "    input_columns=['ANYALC','BINGEDAYS','BI','ALCDRUGS','BT','RT','COSCREEN','DAST','DRUGDAYS','DAYSCOCAINE'], # column(s) containing information about the column we want to impute\n",
    "    output_column='AUDIT', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer7.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions7  = imputer7.predict(df_test)\n",
    "predictions7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions7['AUDIT'], predictions7['AUDIT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions7['AUDIT'], predictions7['AUDIT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions7  = imputer7.predict(df2)\n",
    "predictions7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-bandwidth",
   "metadata": {},
   "source": [
    "### COSCREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer8 = datawig.SimpleImputer(\n",
    "    input_columns=['RT','DAST','BI','AUDIT','DRUGDAYS','MARYJDAYS','BT','ANYALC'], # column(s) containing information about the column we want to impute\n",
    "    output_column='COSCREEN', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer8.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions8  = imputer8.predict(df_test)\n",
    "predictions8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions8['COSCREEN'], predictions8['COSCREEN_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions8['COSCREEN'], predictions8['COSCREEN_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions8  = imputer8.predict(df2)\n",
    "predictions8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-automation",
   "metadata": {},
   "source": [
    "### RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer9 = datawig.SimpleImputer(\n",
    "    input_columns=['DAST','DAYSCOCAINE','COSCREEN','BINGEDAYS','AUDIT','ALCDRUGS','OTHERDRUGS','HALLUC'], # column(s) containing information about the column we want to impute\n",
    "    output_column='RT', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer9.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions9  = imputer9.predict(df_test)\n",
    "predictions9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions9['RT'], predictions9['RT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions9['RT'], predictions9['RT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions9  = imputer9.predict(df2)\n",
    "predictions9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-bunch",
   "metadata": {},
   "source": [
    "### BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer10 = datawig.SimpleImputer(\n",
    "    input_columns=['DAST','ANYALC','AUDIT','DRUGDAYS','MARYJDAYS','ALCDRUGS','TOBMONTH','COSCREEN','AGE'], # column(s) containing information about the column we want to impute\n",
    "    output_column='BI', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer10.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions10  = imputer10.predict(df_test)\n",
    "predictions10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions10['BI'], predictions10['BI_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions10['BI'], predictions10['BI_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions10  = imputer10.predict(df2)\n",
    "predictions10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-wesley",
   "metadata": {},
   "source": [
    "### BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer11 = datawig.SimpleImputer(\n",
    "    input_columns=['DAST','ANYALC','AUDIT','BINGEDAYS','DRUGDAYS','COSCREEN','METHDAYS','ALCDRUGS','MARYJDAYS'], # column(s) containing information about the column we want to impute\n",
    "    output_column='BT', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer11.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions11  = imputer11.predict(df_test)\n",
    "predictions11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions11['BT'], predictions11['BT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions11['BT'], predictions11['BT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions11  = imputer11.predict(df2)\n",
    "predictions11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-glasgow",
   "metadata": {},
   "source": [
    "### INJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer12 = datawig.SimpleImputer(\n",
    "    input_columns=['ANYOPIATEDAYS','DAYSCOCAINE','DAST','ALCDRUGS','BINGEDAYS','DRUGDAYS','RT','BT','COSCREEN'], # column(s) containing information about the column we want to impute\n",
    "    output_column='INJECT', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer12.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions12  = imputer12.predict(df_test)\n",
    "predictions12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions12['INJECT'], predictions12['INJECT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions12['INJECT'], predictions12['INJECT_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions12  = imputer12.predict(df2)\n",
    "predictions12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-fortune",
   "metadata": {},
   "source": [
    "### TOBMONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer13 = datawig.SimpleImputer(\n",
    "    input_columns=['DAST','BI','DAST','DRUGDAYS','MARYJDAYS','AUDIT','RACE','ANYALC','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='TOBMONTH', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer13.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions13  = imputer13.predict(df_test)\n",
    "predictions13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions13['TOBMONTH'], predictions13['TOBMONTH_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions13['TOBMONTH'], predictions13['TOBMONTH_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions13  = imputer13.predict(df2)\n",
    "predictions13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-pizza",
   "metadata": {},
   "source": [
    "### Imputation of numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-reality",
   "metadata": {},
   "source": [
    "### ANYALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer14 = datawig.SimpleImputer(\n",
    "    input_columns=['AUDIT','BINGEDAYS','ALCDRUGS','BI','DAST','DRUGDAYS','RACE','MARYJDAYS','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='ANYALC', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer14.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-cocktail",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions14  = imputer14.predict(df_test)\n",
    "predictions14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rms = mean_squared_error(predictions14['ANYALC'], predictions14['ANYALC_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions14  = imputer14.predict(df2)\n",
    "predictions14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-education",
   "metadata": {},
   "source": [
    "### BINGEDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer15 = datawig.SimpleImputer(\n",
    "    input_columns=['AUDIT','ANYALC','ALCDRUGS','DAYSCOCAINE','BT','RT','DRUGDAYS','MARYJDAYS','DAST'], # column(s) containing information about the column we want to impute\n",
    "    output_column='BINGEDAYS', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer15.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions15  = imputer15.predict(df_test)\n",
    "predictions15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions15['BINGEDAYS'], predictions15['BINGEDAYS_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions15  = imputer15.predict(df2)\n",
    "predictions15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-collins",
   "metadata": {},
   "source": [
    "### DRUGDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer16 = datawig.SimpleImputer(\n",
    "    input_columns=['AUDIT','BINGEDAYS','ALCDRUGS','BI','DAST','DRUGDAYS','RACE','MARYJDAYS','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='DRUGDAYS', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer16.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions16  = imputer16.predict(df_test)\n",
    "predictions16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions16['DRUGDAYS'], predictions16['DRUGDAYS_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions16  = imputer16.predict(df2)\n",
    "predictions16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-desert",
   "metadata": {},
   "source": [
    "### ALCDRUGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer17 = datawig.SimpleImputer(\n",
    "    input_columns=['DRUGDAYS','MARYJDAYS','ANYALC','DAYSCOCAINE','BINGEDAYS','AUDIT','DAST','RT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='ALCDRUGS', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer17.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions17  = imputer17.predict(df_test)\n",
    "predictions17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions17['ALCDRUGS'], predictions17['ALCDRUGS_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions17  = imputer17.predict(df2)\n",
    "predictions17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-summit",
   "metadata": {},
   "source": [
    "### DAYSCOCAINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer18 = datawig.SimpleImputer(\n",
    "    input_columns=['ALCDRUGS','BINGEDAYS','INJECT','RT','AUDIT','ANYALC','DAST','DRUGDAYS','COSCREEN','DAST'], # column(s) containing information about the column we want to impute\n",
    "    output_column='DAYSCOCAINE', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer18.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions18  = imputer18.predict(df_test)\n",
    "predictions18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions18['DAYSCOCAINE'], predictions18['DAYSCOCAINE_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions18  = imputer18.predict(df2)\n",
    "predictions18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-parallel",
   "metadata": {},
   "source": [
    "### MARYJDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer19 = datawig.SimpleImputer(\n",
    "    input_columns=['DRUGDAYS','ALCDRUGS','DAST','BI','ANYALC','COSCREEN','BINGEDAYS','AUDIT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='MARYJDAYS', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer19.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions19  = imputer19.predict(df_test)\n",
    "predictions19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions19['MARYJDAYS'], predictions19['MARYJDAYS_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions19  = imputer19.predict(df2)\n",
    "predictions19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-spanish",
   "metadata": {},
   "source": [
    "### ANYOPIATEDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer20 = datawig.SimpleImputer(\n",
    "    input_columns=['INJECT','DAST','BT','DRUGDAYS','DAYSCOCAINE','ALCDRUGS','BINGEDAYS','RT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='ANYOPIATEDAYS', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer20.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions20  = imputer20.predict(df_test)\n",
    "predictions20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions20['ANYOPIATEDAYS'], predictions20['ANYOPIATEDAYS_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions20  = imputer20.predict(df2)\n",
    "predictions20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-arrow",
   "metadata": {},
   "source": [
    "### METHADONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer21 = datawig.SimpleImputer(\n",
    "    input_columns=['AUDIT','BINGEDAYS','ALCDRUGS','BI','DAST','DRUGDAYS','RACE','MARYJDAYS','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='METHADONE', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer21.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions21  = imputer21.predict(df_test)\n",
    "predictions21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions21['METHADONE'], predictions21['METHADONE_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions21  = imputer14.predict(df2)\n",
    "predictions21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-momentum",
   "metadata": {},
   "source": [
    "### HALLUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer22 = datawig.SimpleImputer(\n",
    "    input_columns=['AUDIT','BINGEDAYS','ALCDRUGS','BI','DAST','DRUGDAYS','RACE','MARYJDAYS','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='HALLUC', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer22.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions22  = imputer22.predict(df_test)\n",
    "predictions22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions22['HALLUC'], predictions22['HALLUC_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions22  = imputer22.predict(df2)\n",
    "predictions22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-hydrogen",
   "metadata": {},
   "source": [
    "### METHDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer23 = datawig.SimpleImputer(\n",
    "    input_columns=['BT','DRUGDAYS','DAST','RT','COSCREEN','RACE','AGE','VET','DEPLOY','TOBMONTH'], # column(s) containing information about the column we want to impute\n",
    "    output_column='METHDAYS', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer23.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions23  = imputer23.predict(df_test)\n",
    "predictions23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions23['METHDAYS'], predictions23['METHDAYS_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions23  = imputer23.predict(df2)\n",
    "predictions23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-climate",
   "metadata": {},
   "source": [
    "### OTHERDRUGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer24 = datawig.SimpleImputer(\n",
    "    input_columns=['AUDIT','BINGEDAYS','ALCDRUGS','BI','DAST','DRUGDAYS','RACE','MARYJDAYS','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='OTHERDRUGS', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer24.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions24  = imputer24.predict(df_test)\n",
    "predictions24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions24['OTHERDRUGS'], predictions24['OTHERDRUGS_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions24  = imputer24.predict(df2)\n",
    "predictions24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-rogers",
   "metadata": {},
   "source": [
    "### AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer25 = datawig.SimpleImputer(\n",
    "    input_columns=['VET','SEX','BI','RACE','DRUGDAYS','ACTIVE','MARYJDAYS','DEPLOY','DAST','HISPANIC'], # column(s) containing information about the column we want to impute\n",
    "    output_column='AGE', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer25.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions25 = imputer25.predict(df_test)\n",
    "predictions25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(predictions25['AGE'], predictions25['AGE_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions25  = imputer25.predict(df2)\n",
    "predictions25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-switzerland",
   "metadata": {},
   "source": [
    "### Case(2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = data_0.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins= [0,21,30,45,60,100]\n",
    "labels = [1,2,3,4,5]\n",
    "df4['AGE'] = pd.cut(df4['AGE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['BINGEDAYS'] = pd.cut(df4['BINGEDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['DRUGDAYS'] = pd.cut(df4['DRUGDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['ALCDRUGS'] = pd.cut(df4['ALCDRUGS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['DAYSCOCAINE'] = pd.cut(df4['DAYSCOCAINE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['MARYJDAYS'] = pd.cut(df4['MARYJDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['ANYOPIATEDAYS'] = pd.cut(df4['ANYOPIATEDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['METHADONE'] = pd.cut(df4['METHADONE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['HALLUC'] = pd.cut(df4['HALLUC'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['METHDAYS'] = pd.cut(df4['METHDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['OTHERDRUGS'] = pd.cut(df4['OTHERDRUGS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df4['ANYALC'] = pd.cut(df4['ANYALC'], bins=bins, labels=labels, right=False)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df4.copy()\n",
    "df3=df3.dropna()\n",
    "df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['DAST'] = df4['DAST'].astype(str)\n",
    "df4['SEX'] = df4['SEX'].astype(str)\n",
    "df4['HISPANIC'] = df4['HISPANIC'].astype(str)\n",
    "df4['RACE'] = df4['RACE'].astype(str)\n",
    "df4['VET'] = df4['VET'].astype(str)\n",
    "df4['ACTIVE'] = df4['ACTIVE'].astype(str)\n",
    "df4['DEPLOY'] = df4['DEPLOY'].astype(str)\n",
    "df4['AUDIT'] = df4['AUDIT'].astype(str)\n",
    "df4['COSCREEN'] = df4['COSCREEN'].astype(str)\n",
    "df4['RT'] = df4['RT'].astype(str)\n",
    "df4['BI'] = df4['BI'].astype(str)\n",
    "df4['BT'] = df4['BT'].astype(str)\n",
    "df4['INJECT'] = df4['INJECT'].astype(str)\n",
    "df4['TOBMONTH'] = df4['TOBMONTH'].astype(str)\n",
    "###############################################################\n",
    "df4['ANYALC'] = df4['ANYALC'].astype(str)\n",
    "df4['BINGEDAYS'] = df4['BINGEDAYS'].astype(str)\n",
    "df4['DRUGDAYS'] = df4['DRUGDAYS'].astype(str)\n",
    "\n",
    "df4['ALCDRUGS'] = df4['ALCDRUGS'].astype(str)\n",
    "df4['DAYSCOCAINE'] = df4['DAYSCOCAINE'].astype(str)\n",
    "df4['MARYJDAYS'] = df4['MARYJDAYS'].astype(str)\n",
    "\n",
    "df4['ANYOPIATEDAYS'] = df4['ANYOPIATEDAYS'].astype(str)\n",
    "df4['METHADONE'] = df4['METHADONE'].astype(str)\n",
    "df4['HALLUC'] = df4['HALLUC'].astype(str)\n",
    "\n",
    "df4['METHDAYS'] = df4['METHDAYS'].astype(str)\n",
    "df4['OTHERDRUGS'] =df4['OTHERDRUGS'].astype(str)\n",
    "df4['AGE'] = df4['AGE'].astype(str)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['DAST'] = df3['DAST'].astype(str)\n",
    "df3['SEX'] = df3['SEX'].astype(str)\n",
    "df3['HISPANIC'] = df3['HISPANIC'].astype(str)\n",
    "df3['RACE'] = df3['RACE'].astype(str)\n",
    "df3['VET'] = df3['VET'].astype(str)\n",
    "df3['ACTIVE'] = df3['ACTIVE'].astype(str)\n",
    "df3['DEPLOY'] = df3['DEPLOY'].astype(str)\n",
    "df3['AUDIT'] = df3['AUDIT'].astype(str)\n",
    "df3['COSCREEN'] = df3['COSCREEN'].astype(str)\n",
    "df3['RT'] = df3['RT'].astype(str)\n",
    "df3['BI'] = df3['BI'].astype(str)\n",
    "df3['BT'] = df3['BT'].astype(str)\n",
    "df3['INJECT'] = df3['INJECT'].astype(str)\n",
    "df3['TOBMONTH'] = df3['TOBMONTH'].astype(str)\n",
    "###############################################################\n",
    "df3['ANYALC'] = df3['ANYALC'].astype(str)\n",
    "df3['BINGEDAYS'] = df3['BINGEDAYS'].astype(str)\n",
    "df3['DRUGDAYS'] = df3['DRUGDAYS'].astype(str)\n",
    "\n",
    "df3['ALCDRUGS'] = df3['ALCDRUGS'].astype(str)\n",
    "df3['DAYSCOCAINE'] = df3['DAYSCOCAINE'].astype(str)\n",
    "df3['MARYJDAYS'] = df3['MARYJDAYS'].astype(str)\n",
    "\n",
    "df3['ANYOPIATEDAYS'] = df3['ANYOPIATEDAYS'].astype(str)\n",
    "df3['METHADONE'] = df3['METHADONE'].astype(str)\n",
    "df3['HALLUC'] = df3['HALLUC'].astype(str)\n",
    "\n",
    "df3['METHDAYS'] = df3['METHDAYS'].astype(str)\n",
    "df3['OTHERDRUGS'] =df3['OTHERDRUGS'].astype(str)\n",
    "df3['AGE'] = df3['AGE'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-plasma",
   "metadata": {},
   "source": [
    "### Imputation of categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-saver",
   "metadata": {},
   "source": [
    "### SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig\n",
    "df_train, df_test = datawig.utils.random_split(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig\n",
    "imputer26 = datawig.SimpleImputer(\n",
    "    input_columns=['VET','AGE','DEPLOY','RACE','HISPANIC','ALCDRUGS','AUDIT','ANYALC'], # column(s) containing information about the column we want to impute\n",
    "    output_column='SEX', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer26.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions26  = imputer26.predict(df_test)\n",
    "predictions26 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Precision Score : \",precision_score(predictions26['SEX'], predictions26['SEX_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions26['SEX'], predictions26['SEX_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions26  = imputer26.predict(df4)\n",
    "predictions26 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-assembly",
   "metadata": {},
   "source": [
    "### RACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer27 = datawig.SimpleImputer(\n",
    "    input_columns=['HISPANIC','SEX','VET','AGE','TOBMONTH','DEPLOY','RT','DAST','MARYJDAYS'], # column(s) containing information about the column we want to impute\n",
    "    output_column='RACE', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer27.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions27  = imputer27.predict(df_test)\n",
    "predictions27 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions27['RACE'], predictions27['RACE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions27['RACE'], predictions27['RACE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions27  = imputer27.predict(df4)\n",
    "predictions27 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-stuart",
   "metadata": {},
   "source": [
    "### TOBMONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer28 = datawig.SimpleImputer(\n",
    "    input_columns=['DAST','BI','DAST','DRUGDAYS','MARYJDAYS','AUDIT','RACE','ANYALC','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='TOBMONTH', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer28.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions28  = imputer28.predict(df_test)\n",
    "predictions28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions28['TOBMONTH'], predictions28['TOBMONTH_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions28['TOBMONTH'], predictions28['TOBMONTH_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions28  = imputer28.predict(df4)\n",
    "predictions28 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-delicious",
   "metadata": {},
   "source": [
    "### ANYALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer29 = datawig.SimpleImputer(\n",
    "    input_columns=['AUDIT','BINGEDAYS','ALCDRUGS','BI','DAST','DRUGDAYS','RACE','MARYJDAYS','BT'], # column(s) containing information about the column we want to impute\n",
    "    output_column='ANYALC', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer29.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions29  = imputer29.predict(df_test)\n",
    "predictions29 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions29['ANYALC'], predictions29['ANYALC_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions29['ANYALC'], predictions29['ANYALC_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rms = mean_squared_error(predictions29['ANYALC'], predictions29['ANYALC_imputed'], squared=False)\n",
    "rms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions29  = imputer29.predict(df4)\n",
    "predictions29 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-survivor",
   "metadata": {},
   "source": [
    "### AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer30 = datawig.SimpleImputer(\n",
    "    input_columns=['VET','SEX','BI','RACE','DRUGDAYS','ACTIVE','MARYJDAYS','DEPLOY','DAST','HISPANIC'], # column(s) containing information about the column we want to impute\n",
    "    output_column='AGE', # the column we'd like to impute values for\n",
    "    output_path = 'imputer_model' # stores model data and metrics\n",
    "    )\n",
    "\n",
    "#Fit an imputer model on the train data\n",
    "imputer30.fit(train_df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions30  = imputer30.predict(df_test)\n",
    "predictions30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(predictions30['AGE'], predictions30['AGE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(predictions30['AGE'], predictions30['AGE_imputed'], \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rms = mean_squared_error(predictions30['AGE'], predictions30['AGE_imputed'], squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions30  = imputer30.predict(df4)\n",
    "predictions30 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-funds",
   "metadata": {},
   "source": [
    "### 4) KNN Imputer (K-Nearest Neighbor)\n",
    "\n",
    "#### * Select K nearest or similar data points using allthe non-missing features\n",
    "#### *Take average ofthe selected data points to ll in the missing feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "convenient-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6553</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6979 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEX  RACE  VET   BI   RT  DEPLOY   AGE  DRUGDAYS  ALCDRUGS  TOBMONTH\n",
       "6553  1.0   2.0  0.0  1.0  0.0     0.0  29.0       NaN       NaN       NaN\n",
       "2111  1.0   2.0  0.0  0.0  0.0     0.0  21.0       0.0       0.0       0.0\n",
       "1161  1.0   1.0  0.0  0.0  0.0     0.0  64.0       0.0       0.0       0.0\n",
       "3796  1.0   2.0  1.0  0.0  0.0     0.0  26.0       0.0       0.0       0.0\n",
       "5039  0.0   2.0  0.0  0.0  0.0     0.0  62.0       0.0       0.0       0.0\n",
       "...   ...   ...  ...  ...  ...     ...   ...       ...       ...       ...\n",
       "3128  1.0   1.0  0.0  0.0  0.0     0.0  51.0       0.0       0.0       1.0\n",
       "5602  1.0   1.0  0.0  0.0  0.0     0.0  78.0       0.0       0.0       0.0\n",
       "3929  1.0   2.0  0.0  0.0  0.0     0.0  28.0       0.0       0.0       0.0\n",
       "138   1.0   2.0  0.0  1.0  0.0     0.0  57.0      27.0       0.0       0.0\n",
       "6506  1.0   2.0  1.0  0.0  1.0     0.0  60.0       NaN       NaN       NaN\n",
       "\n",
       "[6979 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = data_0.copy()\n",
    "df5=df5.sample(frac=1)\n",
    "cols=['SEX' ,'RACE','VET','BI','RT','DEPLOY','AGE'\n",
    "      ,'DRUGDAYS','ALCDRUGS','TOBMONTH']\n",
    "df5=df5[cols]\n",
    "# df5 =pd.read_csv('/home/sameerahtalafha/new_project/new/tables/ALL-original.csv')\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "streaming-seven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3803 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEX  RACE  VET   BI   RT  DEPLOY   AGE  DRUGDAYS  ALCDRUGS  TOBMONTH\n",
       "2111  1.0   2.0  0.0  0.0  0.0     0.0  21.0       0.0       0.0       0.0\n",
       "1161  1.0   1.0  0.0  0.0  0.0     0.0  64.0       0.0       0.0       0.0\n",
       "3796  1.0   2.0  1.0  0.0  0.0     0.0  26.0       0.0       0.0       0.0\n",
       "5039  0.0   2.0  0.0  0.0  0.0     0.0  62.0       0.0       0.0       0.0\n",
       "1411  1.0   2.0  0.0  0.0  0.0     0.0  61.0       0.0       0.0       0.0\n",
       "...   ...   ...  ...  ...  ...     ...   ...       ...       ...       ...\n",
       "2186  0.0   2.0  0.0  0.0  0.0     0.0  45.0       0.0       0.0       0.0\n",
       "3128  1.0   1.0  0.0  0.0  0.0     0.0  51.0       0.0       0.0       1.0\n",
       "5602  1.0   1.0  0.0  0.0  0.0     0.0  78.0       0.0       0.0       0.0\n",
       "3929  1.0   2.0  0.0  0.0  0.0     0.0  28.0       0.0       0.0       0.0\n",
       "138   1.0   2.0  0.0  1.0  0.0     0.0  57.0      27.0       0.0       0.0\n",
       "\n",
       "[3803 rows x 10 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = df5.copy()\n",
    "df6=df6.dropna()\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "congressional-fabric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX         0\n",
       "RACE        0\n",
       "VET         0\n",
       "BI          0\n",
       "RT          0\n",
       "DEPLOY      0\n",
       "AGE         0\n",
       "DRUGDAYS    0\n",
       "ALCDRUGS    0\n",
       "TOBMONTH    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bins= [15,21,35,45,60,100]\n",
    "# labels = [0,1,2,3,4]\n",
    "# df6['AGE'] = pd.cut(df6['AGE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df6['BINGEDAYS'] = pd.cut(df6['BINGEDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df6['DRUGDAYS'] = pd.cut(df6['DRUGDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df6['ALCDRUGS'] = pd.cut(df6['ALCDRUGS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df6['DAYSCOCAINE'] = pd.cut(df6['DAYSCOCAINE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df6['MARYJDAYS'] = pd.cut(df6['MARYJDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df6['METHDAYS'] = pd.cut(df6['METHDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df6['ANYALC'] = pd.cut(df6['ANYALC'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "df6.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "everyday-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df6['DAST'] = df6['DAST'].astype(float).astype(int)\n",
    "# df6['SEX'] = df6['SEX'].astype(float).astype(int)\n",
    "# df6['HISPANIC'] = df6['HISPANIC'].astype(float).astype(int)\n",
    "# df6['RACE'] = df6['RACE'].astype(float).astype(int)\n",
    "# df6['VET'] = df6['VET'].astype(float).astype(int)\n",
    "# df6['ACTIVE'] = df6['ACTIVE'].astype(float).astype(int)\n",
    "# df6['DEPLOY'] = df6['DEPLOY'].astype(float).astype(int)\n",
    "# df6['AUDIT'] = df6['AUDIT'].astype(float).astype(int)\n",
    "# df6['COSCREEN'] = df6['COSCREEN'].astype(float).astype(int)\n",
    "# df6['RT'] = df6['RT'].astype(float).astype(int)\n",
    "# df6['BI'] = df6['BI'].astype(float).astype(int)\n",
    "# df6['BT'] = df6['BT'].astype(float).astype(int)\n",
    "# df6['INJECT'] = df6['INJECT'].astype(float).astype(int)\n",
    "# df6['TOBMONTH'] = df6['TOBMONTH'].astype(float).astype(int)\n",
    "# ###############################################################\n",
    "# df6['ANYALC'] = df6['ANYALC'].astype(float).astype(int)\n",
    "# df6['BINGEDAYS'] = df6['BINGEDAYS'].astype(float).astype(int)\n",
    "# df6['DRUGDAYS'] = df6['DRUGDAYS'].astype(float).astype(int)\n",
    "\n",
    "# df6['ALCDRUGS'] = df6['ALCDRUGS'].astype(float).astype(int)\n",
    "# df6['DAYSCOCAINE'] = df6['DAYSCOCAINE'].astype(float).astype(int)\n",
    "# df6['MARYJDAYS'] = df6['MARYJDAYS'].astype(float).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# df6['METHDAYS'] = df6['METHDAYS'].astype(float).astype(int)\n",
    "\n",
    "# df6['AGE'] = df6['AGE'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "informational-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "df7 = df6.copy()\n",
    "replaced = collections.defaultdict(set)\n",
    "ix = [(row, col) for row in range(df7.shape[0]) for col in range(df7.shape[1])]\n",
    "random.shuffle(ix)\n",
    "to_replace = int(round(.2*len(ix)))\n",
    "for row, col in ix:\n",
    "    if len(replaced[row]) < df7.shape[1] - 1:\n",
    "        df7.iloc[row, col] = np.nan\n",
    "        to_replace -= 1\n",
    "        replaced[row].add(col)\n",
    "        if to_replace == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "corrected-frost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX         798\n",
       "RACE        726\n",
       "VET         740\n",
       "BI          771\n",
       "RT          780\n",
       "DEPLOY      755\n",
       "AGE         791\n",
       "DRUGDAYS    722\n",
       "ALCDRUGS    718\n",
       "TOBMONTH    805\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "published-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_0=np.where(df7['DAST'].isnull())[0]\n",
    "x_0=np.where(df7['SEX'].isnull())[0]\n",
    "#x_2=np.where(df7['HISPANIC'].isnull())[0]\n",
    "x_1=np.where(df7['RACE'].isnull())[0]\n",
    "x_2=np.where(df7['VET'].isnull())[0]\n",
    "#x_5=np.where(df7['ACTIVE'].isnull())[0]\n",
    "x_3=np.where(df7['DEPLOY'].isnull())[0]\n",
    "#x_7=np.where(df7['AUDIT'].isnull())[0]\n",
    "#x_8=np.where(df7['COSCREEN'].isnull())[0]\n",
    "x_4=np.where(df7['BI'].isnull())[0]\n",
    "#x_10=np.where(df7['BT'].isnull())[0]\n",
    "x_5=np.where(df7['RT'].isnull())[0]\n",
    "#x_12=np.where(df7['ANYALC'].isnull())[0]\n",
    "#x_13=np.where(df7['BINGEDAYS'].isnull())[0]\n",
    "x_7=np.where(df7['DRUGDAYS'].isnull())[0]\n",
    "x_8=np.where(df7['ALCDRUGS'].isnull())[0]\n",
    "#x_16=np.where(df7['DAYSCOCAINE'].isnull())[0]\n",
    "#x_17=np.where(df7['MARYJDAYS'].isnull())[0]\n",
    "\n",
    "#x_18=np.where(df7['METHDAYS'].isnull())[0]\n",
    "\n",
    "#x_19=np.where(df7['INJECT'].isnull())[0]\n",
    "x_6=np.where(df7['AGE'].isnull())[0]\n",
    "x_9=np.where(df7['TOBMONTH'].isnull())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "conscious-nowhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005, 1)\n",
      "(3077, 1)\n",
      "(3063, 1)\n",
      "(3048, 1)\n",
      "(3032, 1)\n",
      "(3023, 1)\n",
      "(3081, 1)\n",
      "(3085, 1)\n",
      "(3012, 1)\n",
      "(2998, 1)\n"
     ]
    }
   ],
   "source": [
    "# instatiate both packages to use \n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "imputer = KNN(3)\n",
    "#create a list of categorical columns to iterate over \n",
    "cat_cols =['SEX',  'RACE','VET',  'DEPLOY',  'BI', 'RT',  'DRUGDAYS',\n",
    "       'ALCDRUGS', 'AGE', 'TOBMONTH']\n",
    "\n",
    "def encode(data):\n",
    "    '''function to encode non-null data and replace it in the original data '''\n",
    "    #retain only non-null values \n",
    "    notnulls =np.array(data.dropna())\n",
    "    #reshape the data for encoding\n",
    "    impute_reshape = notnulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    print(impute_reshape.shape)\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Assign back encoded values to non-null values\n",
    "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "    return data\n",
    "\n",
    "#create a for loop to iterate through each column in the data \n",
    "for columns in cat_cols:\n",
    "    encode(df7[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "practical-moore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/3803 with 2 missing, elapsed time: 2.038\n",
      "Imputing row 101/3803 with 1 missing, elapsed time: 2.045\n",
      "Imputing row 201/3803 with 3 missing, elapsed time: 2.050\n",
      "Imputing row 301/3803 with 3 missing, elapsed time: 2.056\n",
      "Imputing row 401/3803 with 3 missing, elapsed time: 2.062\n",
      "Imputing row 501/3803 with 4 missing, elapsed time: 2.067\n",
      "Imputing row 601/3803 with 1 missing, elapsed time: 2.073\n",
      "Imputing row 701/3803 with 3 missing, elapsed time: 2.080\n",
      "Imputing row 801/3803 with 3 missing, elapsed time: 2.086\n",
      "Imputing row 901/3803 with 2 missing, elapsed time: 2.092\n",
      "Imputing row 1001/3803 with 3 missing, elapsed time: 2.098\n",
      "Imputing row 1101/3803 with 2 missing, elapsed time: 2.103\n",
      "Imputing row 1201/3803 with 4 missing, elapsed time: 2.109\n",
      "Imputing row 1301/3803 with 4 missing, elapsed time: 2.115\n",
      "Imputing row 1401/3803 with 3 missing, elapsed time: 2.121\n",
      "Imputing row 1501/3803 with 1 missing, elapsed time: 2.127\n",
      "Imputing row 1601/3803 with 1 missing, elapsed time: 2.132\n",
      "Imputing row 1701/3803 with 2 missing, elapsed time: 2.138\n",
      "Imputing row 1801/3803 with 2 missing, elapsed time: 2.144\n",
      "Imputing row 1901/3803 with 1 missing, elapsed time: 2.150\n",
      "Imputing row 2001/3803 with 4 missing, elapsed time: 2.155\n",
      "Imputing row 2101/3803 with 3 missing, elapsed time: 2.161\n",
      "Imputing row 2201/3803 with 0 missing, elapsed time: 2.167\n",
      "Imputing row 2301/3803 with 3 missing, elapsed time: 2.173\n",
      "Imputing row 2401/3803 with 2 missing, elapsed time: 2.178\n",
      "Imputing row 2501/3803 with 1 missing, elapsed time: 2.184\n",
      "Imputing row 2601/3803 with 0 missing, elapsed time: 2.189\n",
      "Imputing row 2701/3803 with 5 missing, elapsed time: 2.194\n",
      "Imputing row 2801/3803 with 0 missing, elapsed time: 2.200\n",
      "Imputing row 2901/3803 with 1 missing, elapsed time: 2.206\n",
      "Imputing row 3001/3803 with 1 missing, elapsed time: 2.212\n",
      "Imputing row 3101/3803 with 2 missing, elapsed time: 2.218\n",
      "Imputing row 3201/3803 with 2 missing, elapsed time: 2.224\n",
      "Imputing row 3301/3803 with 4 missing, elapsed time: 2.230\n",
      "Imputing row 3401/3803 with 4 missing, elapsed time: 2.235\n",
      "Imputing row 3501/3803 with 3 missing, elapsed time: 2.242\n",
      "Imputing row 3601/3803 with 2 missing, elapsed time: 2.247\n",
      "Imputing row 3701/3803 with 2 missing, elapsed time: 2.254\n",
      "Imputing row 3801/3803 with 1 missing, elapsed time: 2.260\n"
     ]
    }
   ],
   "source": [
    "encode_data = pd.DataFrame(np.round(imputer.fit_transform(df7)),columns = df7.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sapphire-hayes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3803 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEX  RACE  VET   BI   RT  DEPLOY   AGE  DRUGDAYS  ALCDRUGS  TOBMONTH\n",
       "0     1.0   1.0  0.0  0.0  0.0     0.0   2.0       0.0       0.0       0.0\n",
       "1     1.0   0.0  0.0  0.0  0.0     0.0  45.0       0.0       0.0       0.0\n",
       "2     1.0   1.0  1.0  0.0  0.0     0.0   7.0       0.0       0.0       0.0\n",
       "3     0.0   1.0  0.0  0.0  0.0     0.0  43.0       0.0       0.0       0.0\n",
       "4     1.0   1.0  0.0  0.0  0.0     0.0  11.0       0.0       0.0       0.0\n",
       "...   ...   ...  ...  ...  ...     ...   ...       ...       ...       ...\n",
       "3798  0.0   1.0  0.0  0.0  0.0     0.0  13.0       0.0       0.0       0.0\n",
       "3799  1.0   0.0  0.0  0.0  0.0     0.0  32.0       0.0       0.0       1.0\n",
       "3800  1.0   0.0  0.0  0.0  0.0     0.0  59.0       0.0       0.0       0.0\n",
       "3801  1.0   1.0  0.0  0.0  0.0     0.0   9.0       0.0       0.0       0.0\n",
       "3802  1.0   0.0  0.0  0.0  0.0     0.0  38.0      20.0       0.0       0.0\n",
       "\n",
       "[3803 rows x 10 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "provincial-devices",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX         0\n",
       "RACE        0\n",
       "VET         0\n",
       "BI          0\n",
       "RT          0\n",
       "DEPLOY      0\n",
       "AGE         0\n",
       "DRUGDAYS    0\n",
       "ALCDRUGS    0\n",
       "TOBMONTH    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "muslim-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.iloc[:,0] = df6.iloc[:,0].astype(float).astype(int)\n",
    "df6.iloc[:,1] = df6.iloc[:,1].astype(float).astype(int)\n",
    "df6.iloc[:,2] = df6.iloc[:,2].astype(float).astype(int)\n",
    "df6.iloc[:,3] = df6.iloc[:,3].astype(float).astype(int)\n",
    "df6.iloc[:,4] = df6.iloc[:,4].astype(float).astype(int)\n",
    "df6.iloc[:,5] = df6.iloc[:,5].astype(float).astype(int)\n",
    "df6.iloc[:,6] = df6.iloc[:,6].astype(float).astype(int)\n",
    "df6.iloc[:,7]= df6.iloc[:,7].astype(float).astype(int)\n",
    "df6.iloc[:,8] = df6.iloc[:,8].astype(float).astype(int)\n",
    "df6.iloc[:,9] = df6.iloc[:,9].astype(float).astype(int)\n",
    "# df6.iloc[:,10] = df6.iloc[:,10].astype(float).astype(int)\n",
    "# df6.iloc[:,11]= df6.iloc[:,11].astype(float).astype(int)\n",
    "# df6.iloc[:,12]= df6.iloc[:,12].astype(float).astype(int)\n",
    "# df6.iloc[:,13] = df6.iloc[:,13].astype(float).astype(int)\n",
    "# ###############################################################\n",
    "# df6.iloc[:,14] = df6.iloc[:,14].astype(float).astype(int)\n",
    "# df6.iloc[:,15] = df6.iloc[:,15].astype(float).astype(int)\n",
    "# df6.iloc[:,16] = df6.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "# df6.iloc[:,17] = df6.iloc[:,17].astype(float).astype(int)\n",
    "# df6.iloc[:,18]= df6.iloc[:,18].astype(float).astype(int)\n",
    "# df6.iloc[:,19] = df6.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "# df6.iloc[:,20] = df6.iloc[:,20].astype(float).astype(int)\n",
    "# df6.iloc[:,21]= df6.iloc[:,21].astype(float).astype(int)\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "encode_data.iloc[:,0] = encode_data.iloc[:,0].astype(float).astype(int)\n",
    "encode_data.iloc[:,1] = encode_data.iloc[:,1].astype(float).astype(int)\n",
    "encode_data.iloc[:,2] = encode_data.iloc[:,2].astype(float).astype(int)\n",
    "encode_data.iloc[:,3] = encode_data.iloc[:,3].astype(float).astype(int)\n",
    "encode_data.iloc[:,4] = encode_data.iloc[:,4].astype(float).astype(int)\n",
    "encode_data.iloc[:,5] = encode_data.iloc[:,5].astype(float).astype(int)\n",
    "encode_data.iloc[:,6] = encode_data.iloc[:,6].astype(float).astype(int)\n",
    "encode_data.iloc[:,7]= encode_data.iloc[:,7].astype(float).astype(int)\n",
    "encode_data.iloc[:,8] = encode_data.iloc[:,8].astype(float).astype(int)\n",
    "encode_data.iloc[:,9] = encode_data.iloc[:,9].astype(float).astype(int)\n",
    "# encode_data.iloc[:,10] = encode_data.iloc[:,10].astype(float).astype(int)\n",
    "# encode_data.iloc[:,11]= encode_data.iloc[:,11].astype(float).astype(int)\n",
    "# encode_data.iloc[:,12]= encode_data.iloc[:,12].astype(float).astype(int)\n",
    "# encode_data.iloc[:,13] = encode_data.iloc[:,13].astype(float).astype(int)\n",
    "# ###############################################################\n",
    "# encode_data.iloc[:,14] = encode_data.iloc[:,14].astype(float).astype(int)\n",
    "# encode_data.iloc[:,15] = encode_data.iloc[:,15].astype(float).astype(int)\n",
    "# encode_data.iloc[:,16] = encode_data.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "# encode_data.iloc[:,17] = encode_data.iloc[:,17].astype(float).astype(int)\n",
    "# encode_data.iloc[:,18]= encode_data.iloc[:,18].astype(float).astype(int)\n",
    "# encode_data.iloc[:,19] = encode_data.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "# encode_data.iloc[:,20] = encode_data.iloc[:,20].astype(float).astype(int)\n",
    "# encode_data.iloc[:,21]= encode_data.iloc[:,21].astype(float).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "diagnostic-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "3798    0\n",
       "3799    0\n",
       "3800    0\n",
       "3801    0\n",
       "3802    0\n",
       "Name: ALCDRUGS, Length: 3803, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_0=[]\n",
    "for i in x_0:\n",
    "        if(df6.iloc[i,0]==encode_data.iloc[i,0]):\n",
    "            true_0.append(i)\n",
    "true_1=[]\n",
    "for i in x_1:\n",
    "        if(df6.iloc[i,1]==encode_data.iloc[i,1]):\n",
    "            true_1.append(i)\n",
    "true_2=[]\n",
    "for i in x_2:\n",
    "        if(df6.iloc[i,2]==encode_data.iloc[i,2]):\n",
    "            true_2.append(i)\n",
    "true_3=[]\n",
    "for i in x_3:\n",
    "        if(df6.iloc[i,3]==encode_data.iloc[i,3]):\n",
    "            true_3.append(i)\n",
    "\n",
    "true_4=[]\n",
    "for i in x_4:\n",
    "        if(df6.iloc[i,4]==encode_data.iloc[i,4]):\n",
    "            true_4.append(i)\n",
    "   \n",
    "            \n",
    "true_5=[]\n",
    "for i in x_5:\n",
    "        if(df6.iloc[i,5]==encode_data.iloc[i,5]):\n",
    "            true_5.append(i)\n",
    "    \n",
    "true_6=[]\n",
    "for i in x_6:\n",
    "        if(df6.iloc[i,6]==encode_data.iloc[i,6]):\n",
    "            true_6.append(i)\n",
    "\n",
    "true_7=[]\n",
    "for i in x_7:\n",
    "        if(df6.iloc[i,7]==encode_data.iloc[i,7]):\n",
    "            true_7.append(i)\n",
    "true_8=[]\n",
    "for i in x_8:\n",
    "        if(df6.iloc[i,8]==encode_data.iloc[i,8]):\n",
    "            true_8.append(i)\n",
    "true_9=[]\n",
    "for i in x_9:\n",
    "        if(df6.iloc[i,9]==encode_data.iloc[i,9]):\n",
    "            true_9.append(i)\n",
    "# true_10=[]\n",
    "# for i in x_10:\n",
    "#         if(df6.iloc[i,10]==encode_data.iloc[i,10]):\n",
    "#             true_10.append(i)\n",
    "            \n",
    "# true_11=[]\n",
    "# for i in x_11:\n",
    "#         if(df6.iloc[i,11]==encode_data.iloc[i,11]):\n",
    "#             true_11.append(i)\n",
    "            \n",
    "            \n",
    "# true_12=[]\n",
    "# for i in x_12:\n",
    "#         if(df6.iloc[i,12]==encode_data.iloc[i,12]):\n",
    "#             true_12.append(i)\n",
    "            \n",
    "# true_13=[]\n",
    "# for i in x_13:\n",
    "#         if(df6.iloc[i,13]==encode_data.iloc[i,13]):\n",
    "#             true_13.append(i)\n",
    "            \n",
    "            \n",
    "# true_14=[]\n",
    "# for i in x_14:\n",
    "#         if(df6.iloc[i,14]==encode_data.iloc[i,14]):\n",
    "#             true_14.append(i)\n",
    "            \n",
    "# true_15=[]\n",
    "# for i in x_15:\n",
    "#         if(df6.iloc[i,15]==encode_data.iloc[i,15]):\n",
    "#             true_15.append(i)    \n",
    "            \n",
    "# true_16=[]\n",
    "# for i in x_16:\n",
    "#         if(df6.iloc[i,16]==encode_data.iloc[i,16]):\n",
    "#             true_16.append(i)\n",
    "            \n",
    "# true_17=[]\n",
    "# for i in x_17:\n",
    "#         if(df6.iloc[i,17]==encode_data.iloc[i,17]):\n",
    "#             true_17.append(i)\n",
    "            \n",
    "# true_18=[]\n",
    "# for i in x_18:\n",
    "#         if(df6.iloc[i,18]==encode_data.iloc[i,18]):\n",
    "#             true_18.append(i)      \n",
    "            \n",
    "            \n",
    "# true_19=[]\n",
    "# for i in x_19:\n",
    "#         if(df6.iloc[i,19]==encode_data.iloc[i,19]):\n",
    "#             true_19.append(i)   \n",
    "            \n",
    "            \n",
    "# true_20=[]\n",
    "# for i in x_20:\n",
    "#         if(df6.iloc[i,20]==encode_data.iloc[i,20]):\n",
    "#             true_20.append(i)   \n",
    "            \n",
    "            \n",
    "# true_21=[]\n",
    "# for i in x_21:\n",
    "#         if(df6.iloc[i,21]==encode_data.iloc[i,21]):\n",
    "#             true_21.append(i)   \n",
    "            \n",
    "              \n",
    "encode_data.iloc[:,8]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "weighted-rings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2111    21\n",
       "1161    64\n",
       "3796    26\n",
       "5039    62\n",
       "1411    61\n",
       "Name: AGE, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['AGE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "neural-coordinate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6935064935064935\n",
      "0.2276315789473684\n",
      "0.7745358090185677\n",
      "0.982256020278834\n",
      "1.0\n",
      "0.9459459459459459\n",
      "0.003973509933774877\n",
      "0.9585062240663901\n",
      "0.9887920298879203\n",
      "0.7013333333333334\n"
     ]
    }
   ],
   "source": [
    "## Accuracy in each column \n",
    "print(1-((len(x_0)-len(true_0))/len(x_0)))\n",
    "print(1-((len(x_1)-len(true_1))/len(x_1)))\n",
    "print(1-((len(x_2)-len(true_2))/len(x_2)))\n",
    "print(1-((len(x_3)-len(true_3))/len(x_3)))\n",
    "print(1-((len(x_4)-len(true_4))/len(x_4)))\n",
    "print(1-((len(x_5)-len(true_5))/len(x_5)))\n",
    "print(1-((len(x_6)-len(true_6))/len(x_6)))\n",
    "print(1-((len(x_7)-len(true_7))/len(x_7)))\n",
    "print(1-((len(x_8)-len(true_8))/len(x_8)))\n",
    "print(1-((len(x_9)-len(true_9))/len(x_9)))\n",
    "# print(1-((len(x_10)-len(true_10))/len(x_10)))\n",
    "# print(1-((len(x_11)-len(true_11))/len(x_11)))\n",
    "# print(1-((len(x_12)-len(true_12))/len(x_12)))\n",
    "# print(1-((len(x_13)-len(true_13))/len(x_13)))\n",
    "# print(1-((len(x_14)-len(true_14))/len(x_14)))\n",
    "# print(1-((len(x_15)-len(true_15))/len(x_15)))\n",
    "# print(1-((len(x_16)-len(true_16))/len(x_16)))\n",
    "# print(1-((len(x_17)-len(true_17))/len(x_17)))\n",
    "# print(1-((len(x_18)-len(true_18))/len(x_18)))\n",
    "# print(1-((len(x_19)-len(true_19))/len(x_19)))\n",
    "# print(1-((len(x_20)-len(true_20))/len(x_20)))\n",
    "# print(1-((len(x_21)-len(true_21))/len(x_21)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-temple",
   "metadata": {},
   "source": [
    "### Multiple Imputations by Chained Equations (MICE)\n",
    "\n",
    "#### *Perform multiple regressions over random sample ofthe data\n",
    "#### *Take average ofthe multiple regression values\n",
    "#### *Impute the missing feature value for the data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df8 = data_0.copy()\n",
    "df8 =pd.read_csv('/home/sameerahtalafha/new_project/new/tables/ALL1-original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df8.copy()\n",
    "df9=df9.dropna()\n",
    "df9.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins= [15,21,35,45,60,100]\n",
    "labels = [0,1,2,3,4]\n",
    "df9['AGE'] = pd.cut(df9['AGE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df9['BINGEDAYS'] = pd.cut(df9['BINGEDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df9['DRUGDAYS'] = pd.cut(df9['DRUGDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df9['ALCDRUGS'] = pd.cut(df9['ALCDRUGS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df9['DAYSCOCAINE'] = pd.cut(df9['DAYSCOCAINE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df9['MARYJDAYS'] = pd.cut(df9['MARYJDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df9['METHDAYS'] = pd.cut(df9['METHDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df9['ANYALC'] = pd.cut(df9['ANYALC'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "df9.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9['DAST'] = df9['DAST'].astype(float).astype(int)\n",
    "df9['SEX'] = df9['SEX'].astype(float).astype(int)\n",
    "df9['HISPANIC'] = df9['HISPANIC'].astype(float).astype(int)\n",
    "df9['RACE'] = df9['RACE'].astype(float).astype(int)\n",
    "df9['VET'] = df9['VET'].astype(float).astype(int)\n",
    "df9['ACTIVE'] = df9['ACTIVE'].astype(float).astype(int)\n",
    "df9['DEPLOY'] = df9['DEPLOY'].astype(float).astype(int)\n",
    "df9['AUDIT'] = df9['AUDIT'].astype(float).astype(object)\n",
    "df9['COSCREEN'] = df9['COSCREEN'].astype(float).astype(int)\n",
    "df9['RT'] = df9['RT'].astype(float).astype(int)\n",
    "df9['BI'] = df9['BI'].astype(float).astype(int)\n",
    "df9['BT'] = df9['BT'].astype(float).astype(int)\n",
    "df9['INJECT'] = df9['INJECT'].astype(float).astype(int)\n",
    "df9['TOBMONTH'] = df9['TOBMONTH'].astype(float).astype(int)\n",
    "###############################################################\n",
    "df9['ANYALC'] = df9['ANYALC'].astype(float).astype(int)\n",
    "df9['BINGEDAYS'] = df9['BINGEDAYS'].astype(float).astype(int)\n",
    "df9['DRUGDAYS'] = df9['DRUGDAYS'].astype(float).astype(int)\n",
    "\n",
    "df9['ALCDRUGS'] = df9['ALCDRUGS'].astype(float).astype(int)\n",
    "df9['DAYSCOCAINE'] = df9['DAYSCOCAINE'].astype(float).astype(int)\n",
    "df9['MARYJDAYS'] = df9['MARYJDAYS'].astype(float).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df9['METHDAYS'] = df9['METHDAYS'].astype(float).astype(int)\n",
    "\n",
    "df9['AGE'] = df9['AGE'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "df10 = df9.copy()\n",
    "replaced = collections.defaultdict(set)\n",
    "ix = [(row, col) for row in range(df10.shape[0]) for col in range(df10.shape[1])]\n",
    "random.shuffle(ix)\n",
    "to_replace = int(round(.2*len(ix)))\n",
    "for row, col in ix:\n",
    "    if len(replaced[row]) < df10.shape[1] - 1:\n",
    "        df10.iloc[row, col] = np.nan\n",
    "        to_replace -= 1\n",
    "        replaced[row].add(col)\n",
    "        if to_replace == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0=np.where(df10['DAST'].isnull())[0]\n",
    "x_1=np.where(df10['SEX'].isnull())[0]\n",
    "x_2=np.where(df10['HISPANIC'].isnull())[0]\n",
    "x_3=np.where(df10['RACE'].isnull())[0]\n",
    "x_4=np.where(df10['VET'].isnull())[0]\n",
    "x_5=np.where(df10['ACTIVE'].isnull())[0]\n",
    "x_6=np.where(df10['DEPLOY'].isnull())[0]\n",
    "x_7=np.where(df10['AUDIT'].isnull())[0]\n",
    "x_8=np.where(df10['COSCREEN'].isnull())[0]\n",
    "x_9=np.where(df10['BI'].isnull())[0]\n",
    "x_10=np.where(df10['BT'].isnull())[0]\n",
    "x_11=np.where(df10['RT'].isnull())[0]\n",
    "x_12=np.where(df10['ANYALC'].isnull())[0]\n",
    "x_13=np.where(df10['BINGEDAYS'].isnull())[0]\n",
    "x_14=np.where(df10['DRUGDAYS'].isnull())[0]\n",
    "x_15=np.where(df10['ALCDRUGS'].isnull())[0]\n",
    "x_16=np.where(df10['DAYSCOCAINE'].isnull())[0]\n",
    "x_17=np.where(df10['MARYJDAYS'].isnull())[0]\n",
    "\n",
    "x_18=np.where(df10['METHDAYS'].isnull())[0]\n",
    "\n",
    "x_19=np.where(df10['INJECT'].isnull())[0]\n",
    "x_20=np.where(df10['AGE'].isnull())[0]\n",
    "x_21=np.where(df10['TOBMONTH'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate both packages to use \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from fancyimpute import IterativeImputer\n",
    "encoder = OrdinalEncoder()\n",
    "imputer = IterativeImputer()\n",
    "#create a list of categorical columns to iterate over \n",
    "cat_cols =['DAST', 'SEX', 'HISPANIC', 'RACE','VET',  'ACTIVE', 'DEPLOY', 'AUDIT',\n",
    "       'COSCREEN', 'BI', 'BT', 'RT', 'ANYALC', 'BINGEDAYS', 'DRUGDAYS',\n",
    "       'ALCDRUGS', 'DAYSCOCAINE', 'MARYJDAYS', 'METHDAYS', 'INJECT', 'AGE', 'TOBMONTH']\n",
    "\n",
    "def encode(data):\n",
    "    '''function to encode non-null data and replace it in the original data '''\n",
    "    #retain only non-null values \n",
    "    notnulls =np.array(data.dropna())\n",
    "    #reshape the data for encoding\n",
    "    impute_reshape = notnulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    print(impute_reshape.shape)\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Assign back encoded values to non-null values\n",
    "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "    return data\n",
    "\n",
    "#create a for loop to iterate through each column in the data \n",
    "for columns in cat_cols:\n",
    "    encode(df10[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data1 = pd.DataFrame(np.round(imputer.fit_transform(df10)),columns = df10.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.iloc[:,0] = df9.iloc[:,0].astype(float).astype(int)\n",
    "df9.iloc[:,1] = df9.iloc[:,1].astype(float).astype(int)\n",
    "df9.iloc[:,2] = df9.iloc[:,2].astype(float).astype(int)\n",
    "df9.iloc[:,3] = df9.iloc[:,3].astype(float).astype(int)\n",
    "df9.iloc[:,4] = df9.iloc[:,4].astype(float).astype(int)\n",
    "df9.iloc[:,5] = df9.iloc[:,5].astype(float).astype(int)\n",
    "df9.iloc[:,6] = df9.iloc[:,6].astype(float).astype(int)\n",
    "df9.iloc[:,7]= df9.iloc[:,7].astype(float).astype(int)\n",
    "df9.iloc[:,8] = df9.iloc[:,8].astype(float).astype(int)\n",
    "df9.iloc[:,9] = df9.iloc[:,9].astype(float).astype(int)\n",
    "df9.iloc[:,10] = df9.iloc[:,10].astype(float).astype(int)\n",
    "df9.iloc[:,11]= df9.iloc[:,11].astype(float).astype(int)\n",
    "df9.iloc[:,12]= df9.iloc[:,12].astype(float).astype(int)\n",
    "df9.iloc[:,13] = df9.iloc[:,13].astype(float).astype(int)\n",
    "###############################################################\n",
    "df9.iloc[:,14] = df9.iloc[:,14].astype(float).astype(int)\n",
    "df9.iloc[:,15] = df9.iloc[:,15].astype(float).astype(int)\n",
    "df9.iloc[:,16] = df9.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "df9.iloc[:,17] = df9.iloc[:,17].astype(float).astype(int)\n",
    "df9.iloc[:,18]= df9.iloc[:,18].astype(float).astype(int)\n",
    "df9.iloc[:,19] = df9.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "df9.iloc[:,20] = df9.iloc[:,20].astype(float).astype(int)\n",
    "df9.iloc[:,21]= df9.iloc[:,21].astype(float).astype(int)\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "encode_data1.iloc[:,0] = encode_data1.iloc[:,0].astype(float).astype(int)\n",
    "encode_data1.iloc[:,1] = encode_data1.iloc[:,1].astype(float).astype(int)\n",
    "encode_data1.iloc[:,2] = encode_data1.iloc[:,2].astype(float).astype(int)\n",
    "encode_data1.iloc[:,3] = encode_data1.iloc[:,3].astype(float).astype(int)\n",
    "encode_data1.iloc[:,4] = encode_data1.iloc[:,4].astype(float).astype(int)\n",
    "encode_data1.iloc[:,5] = encode_data1.iloc[:,5].astype(float).astype(int)\n",
    "encode_data1.iloc[:,6] = encode_data1.iloc[:,6].astype(float).astype(int)\n",
    "encode_data1.iloc[:,7]= encode_data1.iloc[:,7].astype(float).astype(int)\n",
    "encode_data1.iloc[:,8] = encode_data1.iloc[:,8].astype(float).astype(int)\n",
    "encode_data1.iloc[:,9] = encode_data1.iloc[:,9].astype(float).astype(int)\n",
    "encode_data1.iloc[:,10] = encode_data1.iloc[:,10].astype(float).astype(int)\n",
    "encode_data1.iloc[:,11]= encode_data1.iloc[:,11].astype(float).astype(int)\n",
    "encode_data1.iloc[:,12]= encode_data1.iloc[:,12].astype(float).astype(int)\n",
    "encode_data1.iloc[:,13] = encode_data1.iloc[:,13].astype(float).astype(int)\n",
    "###############################################################\n",
    "encode_data1.iloc[:,14] = encode_data1.iloc[:,14].astype(float).astype(int)\n",
    "encode_data1.iloc[:,15] = encode_data1.iloc[:,15].astype(float).astype(int)\n",
    "encode_data1.iloc[:,16] = encode_data1.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "encode_data1.iloc[:,17] = encode_data1.iloc[:,17].astype(float).astype(int)\n",
    "encode_data1.iloc[:,18]= encode_data1.iloc[:,18].astype(float).astype(int)\n",
    "encode_data1.iloc[:,19] = encode_data1.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "encode_data1.iloc[:,20] = encode_data1.iloc[:,20].astype(float).astype(int)\n",
    "encode_data1.iloc[:,21]= encode_data1.iloc[:,21].astype(float).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_0=[]\n",
    "for i in x_0:\n",
    "        if(df9.iloc[i,0]==encode_data1.iloc[i,0]):\n",
    "            true_0.append(i)\n",
    "true_1=[]\n",
    "for i in x_1:\n",
    "        if(df9.iloc[i,1]==encode_data1.iloc[i,1]):\n",
    "            true_1.append(i)\n",
    "true_2=[]\n",
    "for i in x_2:\n",
    "        if(df9.iloc[i,2]==encode_data1.iloc[i,2]):\n",
    "            true_2.append(i)\n",
    "true_3=[]\n",
    "for i in x_3:\n",
    "        if(df9.iloc[i,3]==encode_data1.iloc[i,3]):\n",
    "            true_3.append(i)\n",
    "\n",
    "true_4=[]\n",
    "for i in x_4:\n",
    "        if(df9.iloc[i,4]==encode_data1.iloc[i,4]):\n",
    "            true_4.append(i)\n",
    "   \n",
    "            \n",
    "true_5=[]\n",
    "for i in x_5:\n",
    "        if(df9.iloc[i,5]==encode_data1.iloc[i,5]):\n",
    "            true_5.append(i)\n",
    "    \n",
    "true_6=[]\n",
    "for i in x_6:\n",
    "        if(df9.iloc[i,6]==encode_data1.iloc[i,6]):\n",
    "            true_6.append(i)\n",
    "\n",
    "true_7=[]\n",
    "for i in x_7:\n",
    "        if(df9.iloc[i,7]==encode_data1.iloc[i,7]):\n",
    "            true_7.append(i)\n",
    "true_8=[]\n",
    "for i in x_8:\n",
    "        if(df9.iloc[i,8]==encode_data1.iloc[i,8]):\n",
    "            true_8.append(i)\n",
    "true_9=[]\n",
    "for i in x_9:\n",
    "        if(df9.iloc[i,9]==encode_data1.iloc[i,9]):\n",
    "            true_9.append(i)\n",
    "true_10=[]\n",
    "for i in x_10:\n",
    "        if(df9.iloc[i,10]==encode_data1.iloc[i,10]):\n",
    "            true_10.append(i)\n",
    "            \n",
    "true_11=[]\n",
    "for i in x_11:\n",
    "        if(df9.iloc[i,11]==encode_data1.iloc[i,11]):\n",
    "            true_11.append(i)\n",
    "            \n",
    "            \n",
    "true_12=[]\n",
    "for i in x_12:\n",
    "        if(df9.iloc[i,12]==encode_data1.iloc[i,12]):\n",
    "            true_12.append(i)\n",
    "            \n",
    "true_13=[]\n",
    "for i in x_13:\n",
    "        if(df9.iloc[i,13]==encode_data1.iloc[i,13]):\n",
    "            true_13.append(i)\n",
    "            \n",
    "            \n",
    "true_14=[]\n",
    "for i in x_14:\n",
    "        if(df9.iloc[i,14]==encode_data1.iloc[i,14]):\n",
    "            true_14.append(i)\n",
    "            \n",
    "true_15=[]\n",
    "for i in x_15:\n",
    "        if(df9.iloc[i,15]==encode_data1.iloc[i,15]):\n",
    "            true_15.append(i)    \n",
    "            \n",
    "true_16=[]\n",
    "for i in x_16:\n",
    "        if(df9.iloc[i,16]==encode_data1.iloc[i,16]):\n",
    "            true_16.append(i)\n",
    "            \n",
    "true_17=[]\n",
    "for i in x_17:\n",
    "        if(df9.iloc[i,17]==encode_data1.iloc[i,17]):\n",
    "            true_17.append(i)\n",
    "            \n",
    "true_18=[]\n",
    "for i in x_18:\n",
    "        if(df9.iloc[i,18]==encode_data1.iloc[i,18]):\n",
    "            true_18.append(i)      \n",
    "            \n",
    "            \n",
    "true_19=[]\n",
    "for i in x_19:\n",
    "        if(df9.iloc[i,19]==encode_data1.iloc[i,19]):\n",
    "            true_19.append(i)   \n",
    "            \n",
    "            \n",
    "true_20=[]\n",
    "for i in x_20:\n",
    "        if(df9.iloc[i,20]==encode_data1.iloc[i,20]):\n",
    "            true_20.append(i)   \n",
    "            \n",
    "            \n",
    "true_21=[]\n",
    "for i in x_21:\n",
    "        if(df9.iloc[i,21]==encode_data1.iloc[i,21]):\n",
    "            true_21.append(i)   \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-adaptation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Accuracy in each column \n",
    "print(1-((len(x_0)-len(true_0))/len(x_0)))\n",
    "print(1-((len(x_1)-len(true_1))/len(x_1)))\n",
    "print(1-((len(x_2)-len(true_2))/len(x_2)))\n",
    "print(1-((len(x_3)-len(true_3))/len(x_3)))\n",
    "print(1-((len(x_4)-len(true_4))/len(x_4)))\n",
    "print(1-((len(x_5)-len(true_5))/len(x_5)))\n",
    "print(1-((len(x_6)-len(true_6))/len(x_6)))\n",
    "print(1-((len(x_7)-len(true_7))/len(x_7)))\n",
    "print(1-((len(x_8)-len(true_8))/len(x_8)))\n",
    "print(1-((len(x_9)-len(true_9))/len(x_9)))\n",
    "print(1-((len(x_10)-len(true_10))/len(x_10)))\n",
    "print(1-((len(x_11)-len(true_11))/len(x_11)))\n",
    "print(1-((len(x_12)-len(true_12))/len(x_12)))\n",
    "print(1-((len(x_13)-len(true_13))/len(x_13)))\n",
    "print(1-((len(x_14)-len(true_14))/len(x_14)))\n",
    "print(1-((len(x_15)-len(true_15))/len(x_15)))\n",
    "print(1-((len(x_16)-len(true_16))/len(x_16)))\n",
    "print(1-((len(x_17)-len(true_17))/len(x_17)))\n",
    "print(1-((len(x_18)-len(true_18))/len(x_18)))\n",
    "print(1-((len(x_19)-len(true_19))/len(x_19)))\n",
    "print(1-((len(x_20)-len(true_20))/len(x_20)))\n",
    "print(1-((len(x_21)-len(true_21))/len(x_21)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-alarm",
   "metadata": {},
   "source": [
    "### The MIDAS : Missing-Data Imputation with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "complete-building",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  RACE  VET  BI  RT  DEPLOY  DRUGDAYS  ALCDRUGS  AGE  TOBMONTH\n",
       "0        0     1    0   0   1       0        11        10   39         1\n",
       "1        1     2    0   0   1       0         4         4   68         0\n",
       "2        0     1    0   0   1       0         0         0   29         1\n",
       "3        1     2    0   1   0       0         1         0   28         0\n",
       "4        0     2    0   0   0       0        20         1   45         0\n",
       "...    ...   ...  ...  ..  ..     ...       ...       ...  ...       ...\n",
       "16905    1     2    0   0   0       0         0         0   82         0\n",
       "16906    1     1    0   0   1       0         0         0   36         1\n",
       "16907    0     1    0   0   1       0         0         0   50         1\n",
       "16908    0     1    0   0   1       0         0         0   49         0\n",
       "16909    0     1    0   0   1       0         0         0   31         1\n",
       "\n",
       "[16910 rows x 10 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df11 = data_0.copy()\n",
    "df11=pd.read_csv('/home/sameerahtalafha/new_project/new/tables/ALL1-original.csv')\n",
    "cols=['SEX' ,'RACE','VET','BI','RT','DEPLOY'\n",
    "      ,'DRUGDAYS','ALCDRUGS','AGE','TOBMONTH']\n",
    "df11=df11[cols]\n",
    "df11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cellular-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  RACE  VET  BI  RT  DEPLOY  DRUGDAYS  ALCDRUGS  AGE  TOBMONTH\n",
       "0        0     1    0   0   1       0        11        10   39         1\n",
       "1        1     2    0   0   1       0         4         4   68         0\n",
       "2        0     1    0   0   1       0         0         0   29         1\n",
       "3        1     2    0   1   0       0         1         0   28         0\n",
       "4        0     2    0   0   0       0        20         1   45         0\n",
       "...    ...   ...  ...  ..  ..     ...       ...       ...  ...       ...\n",
       "16905    1     2    0   0   0       0         0         0   82         0\n",
       "16906    1     1    0   0   1       0         0         0   36         1\n",
       "16907    0     1    0   0   1       0         0         0   50         1\n",
       "16908    0     1    0   0   1       0         0         0   49         0\n",
       "16909    0     1    0   0   1       0         0         0   31         1\n",
       "\n",
       "[16910 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df12 = df11.copy()\n",
    "df12=df11.dropna()\n",
    "df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "capital-taylor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  RACE  VET  BI  RT  DEPLOY DRUGDAYS ALCDRUGS AGE  TOBMONTH\n",
       "0        0     1    0   0   1       0        2        2   2         1\n",
       "1        1     2    0   0   1       0        1        1   4         0\n",
       "2        0     1    0   0   1       0        0        0   1         1\n",
       "3        1     2    0   1   0       0        1        0   1         0\n",
       "4        0     2    0   0   0       0        3        1   3         0\n",
       "...    ...   ...  ...  ..  ..     ...      ...      ...  ..       ...\n",
       "16905    1     2    0   0   0       0        0        0   4         0\n",
       "16906    1     1    0   0   1       0        0        0   2         1\n",
       "16907    0     1    0   0   1       0        0        0   3         1\n",
       "16908    0     1    0   0   1       0        0        0   3         0\n",
       "16909    0     1    0   0   1       0        0        0   1         1\n",
       "\n",
       "[16910 rows x 10 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins= [15,21,35,45,60,100]\n",
    "labels = [0,1,2,3,4]\n",
    "df12['AGE'] = pd.cut(df12['AGE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df12['BINGEDAYS'] = pd.cut(df12['BINGEDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df12['DRUGDAYS'] = pd.cut(df12['DRUGDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,1,10,20,31]\n",
    "labels = [0,1,2,3]\n",
    "df12['ALCDRUGS'] = pd.cut(df12['ALCDRUGS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df12['DAYSCOCAINE'] = pd.cut(df12['DAYSCOCAINE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df12['MARYJDAYS'] = pd.cut(df12['MARYJDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bins= [0,1,10,20,31]\n",
    "# labels = [0,1,2,3]\n",
    "# df12['METHDAYS'] = pd.cut(df12['METHDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "\n",
    "# bins= [0,10,20,30,40]\n",
    "# labels = [1,2,3,4]\n",
    "# df12['ANYALC'] = pd.cut(df12['ANYALC'], bins=bins, labels=labels, right=False)\n",
    "df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "silent-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df12['DAST'] = df12['DAST'].astype(float).astype(int)\n",
    "df12['SEX'] = df12['SEX'].astype(float).astype(int)\n",
    "#df12['HISPANIC'] = df12['HISPANIC'].astype(float).astype(int)\n",
    "df12['RACE'] = df12['RACE'].astype(float).astype(int)\n",
    "df12['VET'] = df12['VET'].astype(float).astype(int)\n",
    "#df12['ACTIVE'] = df12['ACTIVE'].astype(float).astype(int)\n",
    "df12['DEPLOY'] = df12['DEPLOY'].astype(float).astype(int)\n",
    "#df12['AUDIT'] = df12['AUDIT'].astype(float).astype(int)\n",
    "#df12['COSCREEN'] = df12['COSCREEN'].astype(float).astype(int)\n",
    "df12['RT'] = df12['RT'].astype(float).astype(int)\n",
    "df12['BI'] = df12['BI'].astype(float).astype(int)\n",
    "#df12['BT'] = df12['BT'].astype(float).astype(int)\n",
    "#df12['INJECT'] = df12['INJECT'].astype(float).astype(int)\n",
    "df12['TOBMONTH'] = df12['TOBMONTH'].astype(float).astype(int)\n",
    "###############################################################\n",
    "#df12['ANYALC'] = df12['ANYALC'].astype(float).astype(int)\n",
    "#df12['BINGEDAYS'] = df12['BINGEDAYS'].astype(float).astype(int)\n",
    "df12['DRUGDAYS'] = df12['DRUGDAYS'].astype(float).astype(int)\n",
    "\n",
    "df12['ALCDRUGS'] = df12['ALCDRUGS'].astype(float).astype(int)\n",
    "#df12['DAYSCOCAINE'] = df12['DAYSCOCAINE'].astype(float).astype(int)\n",
    "#df12['MARYJDAYS'] = df12['MARYJDAYS'].astype(float).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#df12['METHDAYS'] = df12['METHDAYS'].astype(float).astype(int)\n",
    "\n",
    "df12['AGE'] = df12['AGE'].astype(float).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "published-booking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  RACE  VET  BI  RT  DEPLOY  DRUGDAYS  ALCDRUGS  AGE  TOBMONTH\n",
       "0        0     1    0   0   1       0         2         2    2         1\n",
       "1        1     2    0   0   1       0         1         1    4         0\n",
       "2        0     1    0   0   1       0         0         0    1         1\n",
       "3        1     2    0   1   0       0         1         0    1         0\n",
       "4        0     2    0   0   0       0         3         1    3         0\n",
       "...    ...   ...  ...  ..  ..     ...       ...       ...  ...       ...\n",
       "16905    1     2    0   0   0       0         0         0    4         0\n",
       "16906    1     1    0   0   1       0         0         0    2         1\n",
       "16907    0     1    0   0   1       0         0         0    3         1\n",
       "16908    0     1    0   0   1       0         0         0    3         0\n",
       "16909    0     1    0   0   1       0         0         0    1         1\n",
       "\n",
       "[16910 rows x 10 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df12.isnull().sum()\n",
    "df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "invalid-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.to_csv('MIDAS/out-full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cosmetic-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "df13 = df12.copy()\n",
    "replaced = collections.defaultdict(set)\n",
    "ix = [(row, col) for row in range(df13.shape[0]) for col in range(df13.shape[1])]\n",
    "random.shuffle(ix)\n",
    "to_replace = int(round(.2*len(ix)))\n",
    "for row, col in ix:\n",
    "    if len(replaced[row]) < df13.shape[1] - 1:\n",
    "        df13.iloc[row, col] = np.nan\n",
    "        to_replace -= 1\n",
    "        replaced[row].add(col)\n",
    "        if to_replace == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "established-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13.to_csv('MIDAS/out-miss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cooperative-fireplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX         3455\n",
       "RACE        3353\n",
       "VET         3344\n",
       "BI          3457\n",
       "RT          3299\n",
       "DEPLOY      3392\n",
       "DRUGDAYS    3413\n",
       "ALCDRUGS    3380\n",
       "AGE         3371\n",
       "TOBMONTH    3356\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df13.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "personalized-dominant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  RACE  VET   BI   RT  DEPLOY  DRUGDAYS  ALCDRUGS  AGE  TOBMONTH\n",
       "0      0.0   1.0  0.0  0.0  1.0     NaN       NaN       2.0  2.0       1.0\n",
       "1      1.0   2.0  0.0  0.0  NaN     0.0       1.0       1.0  4.0       NaN\n",
       "2      NaN   1.0  0.0  0.0  1.0     0.0       0.0       0.0  1.0       1.0\n",
       "3      1.0   2.0  0.0  1.0  0.0     NaN       1.0       0.0  1.0       0.0\n",
       "4      NaN   2.0  0.0  0.0  0.0     0.0       3.0       1.0  NaN       NaN\n",
       "...    ...   ...  ...  ...  ...     ...       ...       ...  ...       ...\n",
       "16905  1.0   2.0  NaN  NaN  0.0     0.0       0.0       0.0  4.0       0.0\n",
       "16906  1.0   1.0  0.0  0.0  1.0     0.0       0.0       0.0  2.0       NaN\n",
       "16907  0.0   NaN  0.0  0.0  NaN     0.0       NaN       0.0  3.0       1.0\n",
       "16908  0.0   1.0  0.0  NaN  1.0     0.0       0.0       NaN  3.0       0.0\n",
       "16909  0.0   1.0  0.0  0.0  NaN     0.0       0.0       0.0  1.0       1.0\n",
       "\n",
       "[16910 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df13=pd.read_csv('MIDAS/out-miss.csv')\n",
    "df13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "intermediate-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MIDASpy as md\n",
    "np.random.seed(441)\n",
    "categorical = ['SEX',  'RACE', 'VET', 'DEPLOY', \n",
    "        'BI',  'RT',  'DRUGDAYS',\n",
    "       'ALCDRUGS', 'AGE', 'TOBMONTH' ]\n",
    "data_cat, cat_cols_list = md.cat_conv(df13[categorical])\n",
    "\n",
    "df13=df13.drop(categorical, axis = 1, inplace = True)\n",
    "constructor_list = [df13]\n",
    "constructor_list.append(data_cat)\n",
    "data_in = pd.concat(constructor_list, axis=1)\n",
    "\n",
    "na_loc = data_in.isnull()\n",
    "data_in[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "charitable-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "print(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "seventh-private",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size index: [3, 3, 2, 6, 2, 2, 4, 4, 5, 2]\n",
      "\n",
      "Computation graph constructed\n",
      "\n",
      "Model initialised\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 12:32:21.723634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-12 12:32:21.723656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , loss: 5.579150409635269\n",
      "Epoch: 1 , loss: 4.71179188562162\n",
      "Epoch: 2 , loss: 4.56687775186517\n",
      "Epoch: 3 , loss: 4.523302167879812\n",
      "Epoch: 4 , loss: 4.495336133196498\n",
      "Epoch: 5 , loss: 4.47294744194457\n",
      "Epoch: 6 , loss: 4.45871858185891\n",
      "Epoch: 7 , loss: 4.460717489547802\n",
      "Epoch: 8 , loss: 4.4406908016764755\n",
      "Epoch: 9 , loss: 4.4342966790903695\n",
      "Epoch: 10 , loss: 4.439323556694117\n",
      "Epoch: 11 , loss: 4.4125282299337965\n",
      "Epoch: 12 , loss: 4.408360169918248\n",
      "Epoch: 13 , loss: 4.41234044979016\n",
      "Epoch: 14 , loss: 4.392377692641634\n",
      "Epoch: 15 , loss: 4.411127327292254\n",
      "Epoch: 16 , loss: 4.410724212951733\n",
      "Epoch: 17 , loss: 4.3920331446058825\n",
      "Epoch: 18 , loss: 4.394383528693155\n",
      "Epoch: 19 , loss: 4.404772814476129\n",
      "Epoch: 20 , loss: 4.4117400185628375\n",
      "Epoch: 21 , loss: 4.389751402943423\n",
      "Epoch: 22 , loss: 4.414091655476526\n",
      "Epoch: 23 , loss: 4.4073565839366475\n",
      "Epoch: 24 , loss: 4.394938779599739\n",
      "Epoch: 25 , loss: 4.410721169050896\n",
      "Epoch: 26 , loss: 4.384146653567299\n",
      "Epoch: 27 , loss: 4.3848283609206025\n",
      "Epoch: 28 , loss: 4.387413898426475\n",
      "Epoch: 29 , loss: 4.390786041816075\n",
      "Epoch: 30 , loss: 4.385157206067533\n",
      "Epoch: 31 , loss: 4.395824193051367\n",
      "Epoch: 32 , loss: 4.390757379658295\n",
      "Epoch: 33 , loss: 4.365458363159136\n",
      "Epoch: 34 , loss: 4.41086910303795\n",
      "Epoch: 35 , loss: 4.392373066056859\n",
      "Epoch: 36 , loss: 4.375998727074175\n",
      "Epoch: 37 , loss: 4.374810931131695\n",
      "Epoch: 38 , loss: 4.36688675054095\n",
      "Epoch: 39 , loss: 4.3772161860357635\n",
      "Epoch: 40 , loss: 4.363212018527768\n",
      "Epoch: 41 , loss: 4.385729342699051\n",
      "Epoch: 42 , loss: 4.385972385153626\n",
      "Epoch: 43 , loss: 4.389766985042528\n",
      "Epoch: 44 , loss: 4.362964616128893\n",
      "Epoch: 45 , loss: 4.357990945153164\n",
      "Epoch: 46 , loss: 4.366595702189388\n",
      "Epoch: 47 , loss: 4.377231252464381\n",
      "Epoch: 48 , loss: 4.3845339031382045\n",
      "Epoch: 49 , loss: 4.3861152888699015\n",
      "Epoch: 50 , loss: 4.359393888124914\n",
      "Epoch: 51 , loss: 4.386288058577162\n",
      "Epoch: 52 , loss: 4.374864585923426\n",
      "Epoch: 53 , loss: 4.371506438788139\n",
      "Epoch: 54 , loss: 4.376092762432315\n",
      "Epoch: 55 , loss: 4.36702816955971\n",
      "Epoch: 56 , loss: 4.378456303793373\n",
      "Epoch: 57 , loss: 4.3879179128191685\n",
      "Epoch: 58 , loss: 4.373469543050636\n",
      "Epoch: 59 , loss: 4.378301270983436\n",
      "Epoch: 60 , loss: 4.37623247097839\n",
      "Epoch: 61 , loss: 4.3570508999806465\n",
      "Epoch: 62 , loss: 4.371022994545373\n",
      "Epoch: 63 , loss: 4.353821123413967\n",
      "Epoch: 64 , loss: 4.3626030742219\n",
      "Epoch: 65 , loss: 4.344809713462989\n",
      "Epoch: 66 , loss: 4.340828487818891\n",
      "Epoch: 67 , loss: 4.3536102726604\n",
      "Epoch: 68 , loss: 4.376895850354975\n",
      "Epoch: 69 , loss: 4.345019781905593\n",
      "Epoch: 70 , loss: 4.359303506260568\n",
      "Epoch: 71 , loss: 4.356686497276479\n",
      "Epoch: 72 , loss: 4.335282005821213\n",
      "Epoch: 73 , loss: 4.363263360252886\n",
      "Epoch: 74 , loss: 4.366974400751518\n",
      "Epoch: 75 , loss: 4.367858856013327\n",
      "Epoch: 76 , loss: 4.344473096005844\n",
      "Epoch: 77 , loss: 4.361381961992293\n",
      "Epoch: 78 , loss: 4.332538348255736\n",
      "Epoch: 79 , loss: 4.347621935560848\n",
      "Epoch: 80 , loss: 4.332715698941187\n",
      "Epoch: 81 , loss: 4.365157831573125\n",
      "Epoch: 82 , loss: 4.3578231619163\n",
      "Epoch: 83 , loss: 4.362846227080533\n",
      "Epoch: 84 , loss: 4.332169054358294\n",
      "Epoch: 85 , loss: 4.338398871999798\n",
      "Epoch: 86 , loss: 4.325611785279982\n",
      "Epoch: 87 , loss: 4.349287823971474\n",
      "Epoch: 88 , loss: 4.332746567825477\n",
      "Epoch: 89 , loss: 4.323485609031085\n",
      "Epoch: 90 , loss: 4.336772865418232\n",
      "Epoch: 91 , loss: 4.320747989370967\n",
      "Epoch: 92 , loss: 4.330508419735865\n",
      "Epoch: 93 , loss: 4.325620404021307\n",
      "Epoch: 94 , loss: 4.331277984561342\n",
      "Epoch: 95 , loss: 4.3358759794271355\n",
      "Epoch: 96 , loss: 4.327771679244258\n",
      "Epoch: 97 , loss: 4.336155777627772\n",
      "Epoch: 98 , loss: 4.333708922068278\n",
      "Epoch: 99 , loss: 4.329472031105649\n",
      "Epoch: 100 , loss: 4.319312443561627\n",
      "Epoch: 101 , loss: 4.349346373117331\n",
      "Epoch: 102 , loss: 4.345392110447089\n",
      "Epoch: 103 , loss: 4.312404134959886\n",
      "Epoch: 104 , loss: 4.31425477135362\n",
      "Epoch: 105 , loss: 4.341851225856579\n",
      "Epoch: 106 , loss: 4.321754496205937\n",
      "Epoch: 107 , loss: 4.320691364506881\n",
      "Epoch: 108 , loss: 4.323517164497664\n",
      "Epoch: 109 , loss: 4.336243374329625\n",
      "Epoch: 110 , loss: 4.313589764363838\n",
      "Epoch: 111 , loss: 4.305785975898758\n",
      "Epoch: 112 , loss: 4.309246873991056\n",
      "Epoch: 113 , loss: 4.325092939264847\n",
      "Epoch: 114 , loss: 4.3232635605064305\n",
      "Epoch: 115 , loss: 4.316231862839424\n",
      "Epoch: 116 , loss: 4.3262838301333515\n",
      "Epoch: 117 , loss: 4.311349200254137\n",
      "Epoch: 118 , loss: 4.311901085756042\n",
      "Epoch: 119 , loss: 4.31993424260255\n",
      "Epoch: 120 , loss: 4.337175786946759\n",
      "Epoch: 121 , loss: 4.309880094772035\n",
      "Epoch: 122 , loss: 4.297555854374712\n",
      "Epoch: 123 , loss: 4.3121528909965\n",
      "Epoch: 124 , loss: 4.3110228275710885\n",
      "Epoch: 125 , loss: 4.298429879726785\n",
      "Epoch: 126 , loss: 4.296468459295504\n",
      "Epoch: 127 , loss: 4.313970521995516\n",
      "Epoch: 128 , loss: 4.301221309286175\n",
      "Epoch: 129 , loss: 4.29854436105851\n",
      "Epoch: 130 , loss: 4.303832747267954\n",
      "Epoch: 131 , loss: 4.32823918940443\n",
      "Epoch: 132 , loss: 4.3273258861718755\n",
      "Epoch: 133 , loss: 4.311936625702814\n",
      "Epoch: 134 , loss: 4.330589120360938\n",
      "Epoch: 135 , loss: 4.3056222609046735\n",
      "Epoch: 136 , loss: 4.294827692888\n",
      "Epoch: 137 , loss: 4.2988895396843105\n",
      "Epoch: 138 , loss: 4.308520260182294\n",
      "Epoch: 139 , loss: 4.301210538907484\n",
      "Epoch: 140 , loss: 4.316063263651096\n",
      "Epoch: 141 , loss: 4.318741941316561\n",
      "Epoch: 142 , loss: 4.311176471412182\n",
      "Epoch: 143 , loss: 4.31620275816231\n",
      "Epoch: 144 , loss: 4.29737470321583\n",
      "Epoch: 145 , loss: 4.290064716429422\n",
      "Epoch: 146 , loss: 4.312949267978018\n",
      "Epoch: 147 , loss: 4.308993559217814\n",
      "Epoch: 148 , loss: 4.307397184724158\n",
      "Epoch: 149 , loss: 4.3130713527401285\n",
      "Epoch: 150 , loss: 4.3004647714622095\n",
      "Epoch: 151 , loss: 4.305465717884627\n",
      "Epoch: 152 , loss: 4.292746916864857\n",
      "Epoch: 153 , loss: 4.318520457681381\n",
      "Epoch: 154 , loss: 4.309344815485405\n",
      "Epoch: 155 , loss: 4.304688923512444\n",
      "Epoch: 156 , loss: 4.299663074314594\n",
      "Epoch: 157 , loss: 4.296449847745173\n",
      "Epoch: 158 , loss: 4.319504468052676\n",
      "Epoch: 159 , loss: 4.3062811096509295\n",
      "Epoch: 160 , loss: 4.311812070283023\n",
      "Epoch: 161 , loss: 4.300999408870032\n",
      "Epoch: 162 , loss: 4.30323287934968\n",
      "Epoch: 163 , loss: 4.316333550846938\n",
      "Epoch: 164 , loss: 4.302980691646084\n",
      "Epoch: 165 , loss: 4.308034643530846\n",
      "Epoch: 166 , loss: 4.318530757996169\n",
      "Epoch: 167 , loss: 4.2982393058412\n",
      "Epoch: 168 , loss: 4.313983734358441\n",
      "Epoch: 169 , loss: 4.317232137376612\n",
      "Epoch: 170 , loss: 4.2953557670116425\n",
      "Epoch: 171 , loss: 4.301527378911322\n",
      "Epoch: 172 , loss: 4.299069646407258\n",
      "Epoch: 173 , loss: 4.302297548362703\n",
      "Epoch: 174 , loss: 4.298361483848456\n",
      "Epoch: 175 , loss: 4.2838952830343535\n",
      "Epoch: 176 , loss: 4.310378694173061\n",
      "Epoch: 177 , loss: 4.315436400698893\n",
      "Epoch: 178 , loss: 4.3275658041238785\n",
      "Epoch: 179 , loss: 4.321834414068497\n",
      "Epoch: 180 , loss: 4.296702898361466\n",
      "Epoch: 181 , loss: 4.318552253372742\n",
      "Epoch: 182 , loss: 4.311367178053567\n",
      "Epoch: 183 , loss: 4.285634033381939\n",
      "Epoch: 184 , loss: 4.30223564397205\n",
      "Epoch: 185 , loss: 4.3034016119711325\n",
      "Epoch: 186 , loss: 4.310433596372604\n",
      "Epoch: 187 , loss: 4.300074816878998\n",
      "Epoch: 188 , loss: 4.297166425847646\n",
      "Epoch: 189 , loss: 4.284154309919386\n",
      "Epoch: 190 , loss: 4.328756387938153\n",
      "Epoch: 191 , loss: 4.301178654712258\n",
      "Epoch: 192 , loss: 4.308149022586418\n",
      "Epoch: 193 , loss: 4.294028834411592\n",
      "Epoch: 194 , loss: 4.3019895036563724\n",
      "Epoch: 195 , loss: 4.288523684848439\n",
      "Epoch: 196 , loss: 4.322239252428214\n",
      "Epoch: 197 , loss: 4.299527782608163\n",
      "Epoch: 198 , loss: 4.296869582976356\n",
      "Epoch: 199 , loss: 4.312557283901807\n",
      "Training complete. Saving file...\n",
      "Model saved in file: tmp/MIDAS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MIDASpy.midas_base.Midas at 0x7ff950956f70>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = md.Midas(layer_structure = [300,300], vae_layer = False, seed = 89, input_drop = 0.2)\n",
    "imputer.build_model(data_in, softmax_columns = cat_cols_list)\n",
    "imputer.train_model(training_epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "contained-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/MIDAS\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 12:37:24.232056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-12 12:37:24.232077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "imputations = imputer.generate_samples(m=10).output_list \n",
    "n=1\n",
    "for i in imputations:\n",
    "    file_out = \"MIDAS/midas_imp_\" + str(n) + \".csv\"\n",
    "    i.to_csv(file_out, index=False)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "increased-immunology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX_0.0         0\n",
       "SEX_1.0         0\n",
       "SEX_2.0         0\n",
       "RACE_1.0        0\n",
       "RACE_2.0        0\n",
       "RACE_3.0        0\n",
       "VET_0.0         0\n",
       "VET_1.0         0\n",
       "DEPLOY_0.0      0\n",
       "DEPLOY_1.0      0\n",
       "DEPLOY_2.0      0\n",
       "DEPLOY_3.0      0\n",
       "DEPLOY_4.0      0\n",
       "DEPLOY_5.0      0\n",
       "BI_0.0          0\n",
       "BI_1.0          0\n",
       "RT_0.0          0\n",
       "RT_1.0          0\n",
       "DRUGDAYS_0.0    0\n",
       "DRUGDAYS_1.0    0\n",
       "DRUGDAYS_2.0    0\n",
       "DRUGDAYS_3.0    0\n",
       "ALCDRUGS_0.0    0\n",
       "ALCDRUGS_1.0    0\n",
       "ALCDRUGS_2.0    0\n",
       "ALCDRUGS_3.0    0\n",
       "AGE_0.0         0\n",
       "AGE_1.0         0\n",
       "AGE_2.0         0\n",
       "AGE_3.0         0\n",
       "AGE_4.0         0\n",
       "TOBMONTH_0.0    0\n",
       "TOBMONTH_1.0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_data2 =  pd.read_csv('MIDAS/midas_imp_7.csv') \n",
    "encode_data2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "civilian-fashion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX_0.0</th>\n",
       "      <th>SEX_1.0</th>\n",
       "      <th>SEX_2.0</th>\n",
       "      <th>RACE_1.0</th>\n",
       "      <th>RACE_2.0</th>\n",
       "      <th>RACE_3.0</th>\n",
       "      <th>VET_0.0</th>\n",
       "      <th>VET_1.0</th>\n",
       "      <th>DEPLOY_0.0</th>\n",
       "      <th>DEPLOY_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>ALCDRUGS_1.0</th>\n",
       "      <th>ALCDRUGS_2.0</th>\n",
       "      <th>ALCDRUGS_3.0</th>\n",
       "      <th>AGE_0.0</th>\n",
       "      <th>AGE_1.0</th>\n",
       "      <th>AGE_2.0</th>\n",
       "      <th>AGE_3.0</th>\n",
       "      <th>AGE_4.0</th>\n",
       "      <th>TOBMONTH_0.0</th>\n",
       "      <th>TOBMONTH_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831383</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731069</td>\n",
       "      <td>0.268931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776864</td>\n",
       "      <td>0.223045</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957236</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.762074</td>\n",
       "      <td>0.237756</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.44331</td>\n",
       "      <td>0.257709</td>\n",
       "      <td>0.21635</td>\n",
       "      <td>0.063548</td>\n",
       "      <td>0.645944</td>\n",
       "      <td>0.354056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876935</td>\n",
       "      <td>0.123065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567055</td>\n",
       "      <td>0.432945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825747</td>\n",
       "      <td>0.171682</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.054841</td>\n",
       "      <td>0.046434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SEX_0.0   SEX_1.0   SEX_2.0  RACE_1.0  RACE_2.0  RACE_3.0   VET_0.0  \\\n",
       "0      1.000000  0.000000  0.000000  1.000000  0.000000  0.000000  1.000000   \n",
       "1      0.000000  1.000000  0.000000  0.000000  1.000000  0.000000  1.000000   \n",
       "2      0.776864  0.223045  0.000091  1.000000  0.000000  0.000000  1.000000   \n",
       "3      0.000000  1.000000  0.000000  0.000000  1.000000  0.000000  1.000000   \n",
       "4      0.762074  0.237756  0.000170  0.000000  1.000000  0.000000  1.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "16905  0.000000  1.000000  0.000000  0.000000  1.000000  0.000000  0.876935   \n",
       "16906  0.000000  1.000000  0.000000  1.000000  0.000000  0.000000  1.000000   \n",
       "16907  1.000000  0.000000  0.000000  0.825747  0.171682  0.002571  1.000000   \n",
       "16908  1.000000  0.000000  0.000000  1.000000  0.000000  0.000000  1.000000   \n",
       "16909  1.000000  0.000000  0.000000  1.000000  0.000000  0.000000  1.000000   \n",
       "\n",
       "        VET_1.0  DEPLOY_0.0  DEPLOY_1.0  ...  ALCDRUGS_1.0  ALCDRUGS_2.0  \\\n",
       "0      0.000000    0.831383    0.003598  ...      0.000000      1.000000   \n",
       "1      0.000000    1.000000    0.000000  ...      1.000000      0.000000   \n",
       "2      0.000000    1.000000    0.000000  ...      0.000000      0.000000   \n",
       "3      0.000000    0.957236    0.005277  ...      0.000000      0.000000   \n",
       "4      0.000000    1.000000    0.000000  ...      1.000000      0.000000   \n",
       "...         ...         ...         ...  ...           ...           ...   \n",
       "16905  0.123065    1.000000    0.000000  ...      0.000000      0.000000   \n",
       "16906  0.000000    1.000000    0.000000  ...      0.000000      0.000000   \n",
       "16907  0.000000    1.000000    0.000000  ...      0.000000      0.000000   \n",
       "16908  0.000000    1.000000    0.000000  ...      0.055446      0.054841   \n",
       "16909  0.000000    1.000000    0.000000  ...      0.000000      0.000000   \n",
       "\n",
       "       ALCDRUGS_3.0   AGE_0.0  AGE_1.0   AGE_2.0  AGE_3.0   AGE_4.0  \\\n",
       "0          0.000000  0.000000  0.00000  1.000000  0.00000  0.000000   \n",
       "1          0.000000  0.000000  0.00000  0.000000  0.00000  1.000000   \n",
       "2          0.000000  0.000000  1.00000  0.000000  0.00000  0.000000   \n",
       "3          0.000000  0.000000  1.00000  0.000000  0.00000  0.000000   \n",
       "4          0.000000  0.019084  0.44331  0.257709  0.21635  0.063548   \n",
       "...             ...       ...      ...       ...      ...       ...   \n",
       "16905      0.000000  0.000000  0.00000  0.000000  0.00000  1.000000   \n",
       "16906      0.000000  0.000000  0.00000  1.000000  0.00000  0.000000   \n",
       "16907      0.000000  0.000000  0.00000  0.000000  1.00000  0.000000   \n",
       "16908      0.046434  0.000000  0.00000  0.000000  1.00000  0.000000   \n",
       "16909      0.000000  0.000000  1.00000  0.000000  0.00000  0.000000   \n",
       "\n",
       "       TOBMONTH_0.0  TOBMONTH_1.0  \n",
       "0          0.000000      1.000000  \n",
       "1          0.731069      0.268931  \n",
       "2          0.000000      1.000000  \n",
       "3          1.000000      0.000000  \n",
       "4          0.645944      0.354056  \n",
       "...             ...           ...  \n",
       "16905      1.000000      0.000000  \n",
       "16906      0.567055      0.432945  \n",
       "16907      0.000000      1.000000  \n",
       "16908      1.000000      0.000000  \n",
       "16909      0.000000      1.000000  \n",
       "\n",
       "[16910 rows x 33 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "western-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fixed-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df13 = undummify(encode_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bridal-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  RACE  VET  DEPLOY  BI  RT  DRUGDAYS  ALCDRUGS  AGE  TOBMONTH\n",
       "0        0     1    0       0   0   1         2         2    2         1\n",
       "1        1     2    0       0   0   0         1         1    4         0\n",
       "2        0     1    0       0   0   1         0         0    1         1\n",
       "3        1     2    0       0   1   0         1         0    1         0\n",
       "4        0     2    0       0   0   0         3         1    1         0\n",
       "...    ...   ...  ...     ...  ..  ..       ...       ...  ...       ...\n",
       "16905    1     2    0       0   0   0         0         0    4         0\n",
       "16906    1     1    0       0   0   1         0         0    2         0\n",
       "16907    0     1    0       0   0   1         0         0    3         1\n",
       "16908    0     1    0       0   0   1         0         0    3         0\n",
       "16909    0     1    0       0   0   0         0         0    1         1\n",
       "\n",
       "[16910 rows x 10 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return_df13['DAST'] = return_df13['DAST'].astype(float).astype(int)\n",
    "return_df13['SEX'] = return_df13['SEX'].astype(float).astype(int)\n",
    "#return_df13['HISPANIC'] = return_df13['HISPANIC'].astype(float).astype(int)\n",
    "return_df13['RACE'] = return_df13['RACE'].astype(float).astype(int)\n",
    "return_df13['VET'] = return_df13['VET'].astype(float).astype(int)\n",
    "#return_df13['ACTIVE'] = return_df13['ACTIVE'].astype(float).astype(int)\n",
    "return_df13['DEPLOY'] = return_df13['DEPLOY'].astype(float).astype(int)\n",
    "#return_df13['AUDIT'] = return_df13['AUDIT'].astype(float).astype(int)\n",
    "#return_df13['COSCREEN'] = return_df13['COSCREEN'].astype(float).astype(int)\n",
    "return_df13['RT'] = return_df13['RT'].astype(float).astype(int)\n",
    "return_df13['BI'] = return_df13['BI'].astype(float).astype(int)\n",
    "#return_df13['BT'] = return_df13['BT'].astype(float).astype(int)\n",
    "#return_df13['INJECT'] = return_df13['INJECT'].astype(float).astype(int)\n",
    "return_df13['TOBMONTH'] = return_df13['TOBMONTH'].astype(float).astype(int)\n",
    "###############################################################\n",
    "#return_df13['ANYALC'] = return_df13['ANYALC'].astype(float).astype(int)\n",
    "#return_df13['BINGEDAYS'] = return_df13['BINGEDAYS'].astype(float).astype(int)\n",
    "return_df13['DRUGDAYS'] = return_df13['DRUGDAYS'].astype(float).astype(int)\n",
    "\n",
    "return_df13['ALCDRUGS'] = return_df13['ALCDRUGS'].astype(float).astype(int)\n",
    "#return_df13['DAYSCOCAINE'] = return_df13['DAYSCOCAINE'].astype(float).astype(int)\n",
    "#return_df13['MARYJDAYS'] = return_df13['MARYJDAYS'].astype(float).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#return_df13['METHDAYS'] = return_df13['METHDAYS'].astype(float).astype(int)\n",
    "\n",
    "return_df13['AGE'] = return_df13['AGE'].astype(float).astype(int)\n",
    "return_df13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "directed-mambo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACE</th>\n",
       "      <th>VET</th>\n",
       "      <th>BI</th>\n",
       "      <th>RT</th>\n",
       "      <th>DEPLOY</th>\n",
       "      <th>DRUGDAYS</th>\n",
       "      <th>ALCDRUGS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TOBMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16909</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  RACE  VET  BI  RT  DEPLOY  DRUGDAYS  ALCDRUGS  AGE  TOBMONTH\n",
       "0        0     1    0   0   1       0         2         2    2         1\n",
       "1        1     2    0   0   1       0         1         1    4         0\n",
       "2        0     1    0   0   1       0         0         0    1         1\n",
       "3        1     2    0   1   0       0         1         0    1         0\n",
       "4        0     2    0   0   0       0         3         1    3         0\n",
       "...    ...   ...  ...  ..  ..     ...       ...       ...  ...       ...\n",
       "16905    1     2    0   0   0       0         0         0    4         0\n",
       "16906    1     1    0   0   1       0         0         0    2         1\n",
       "16907    0     1    0   0   1       0         0         0    3         1\n",
       "16908    0     1    0   0   1       0         0         0    3         0\n",
       "16909    0     1    0   0   1       0         0         0    1         1\n",
       "\n",
       "[16910 rows x 10 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df12=pd.read_csv('MIDAS/out-full.csv')\n",
    "#df12['DAST'] = df12['DAST'].astype(float).astype(int)\n",
    "df12['SEX'] = df12['SEX'].astype(float).astype(int)\n",
    "#df12['HISPANIC'] = df12['HISPANIC'].astype(float).astype(int)\n",
    "df12['RACE'] = df12['RACE'].astype(float).astype(int)\n",
    "df12['VET'] = df12['VET'].astype(float).astype(int)\n",
    "#df12['ACTIVE'] = df12['ACTIVE'].astype(float).astype(int)\n",
    "df12['DEPLOY'] = df12['DEPLOY'].astype(float).astype(int)\n",
    "#df12['AUDIT'] = df12['AUDIT'].astype(float).astype(int)\n",
    "#df12['COSCREEN'] = df12['COSCREEN'].astype(float).astype(int)\n",
    "df12['RT'] = df12['RT'].astype(float).astype(int)\n",
    "df12['BI'] = df12['BI'].astype(float).astype(int)\n",
    "#df12['BT'] = df12['BT'].astype(float).astype(int)\n",
    "#df12['INJECT'] = df12['INJECT'].astype(float).astype(int)\n",
    "df12['TOBMONTH'] = df12['TOBMONTH'].astype(float).astype(int)\n",
    "###############################################################\n",
    "#df12['ANYALC'] = df12['ANYALC'].astype(float).astype(int)\n",
    "#df12['BINGEDAYS'] = df12['BINGEDAYS'].astype(float).astype(int)\n",
    "df12['DRUGDAYS'] = df12['DRUGDAYS'].astype(float).astype(int)\n",
    "\n",
    "df12['ALCDRUGS'] = df12['ALCDRUGS'].astype(float).astype(int)\n",
    "#df12['DAYSCOCAINE'] = df12['DAYSCOCAINE'].astype(float).astype(int)\n",
    "#df12['MARYJDAYS'] = df12['MARYJDAYS'].astype(float).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#df12['METHDAYS'] = df12['METHDAYS'].astype(float).astype(int)\n",
    "\n",
    "df12['AGE'] = df12['AGE'].astype(float).astype(int)\n",
    "df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "blocked-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13=pd.read_csv('MIDAS/out-miss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "desirable-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_0=np.where(df13['DAST'].isnull())[0]\n",
    "x_0=np.where(df13['SEX'].isnull())[0]\n",
    "#x_2=np.where(df13['HISPANIC'].isnull())[0]\n",
    "x_1=np.where(df13['RACE'].isnull())[0]\n",
    "x_2=np.where(df13['VET'].isnull())[0]\n",
    "#x_5=np.where(df13['ACTIVE'].isnull())[0]\n",
    "x_3=np.where(df13['DEPLOY'].isnull())[0]\n",
    "#x_7=np.where(df13['AUDIT'].isnull())[0]\n",
    "#x_8=np.where(df13['COSCREEN'].isnull())[0]\n",
    "x_4=np.where(df13['BI'].isnull())[0]\n",
    "#x_10=np.where(df13['BT'].isnull())[0]\n",
    "x_5=np.where(df13['RT'].isnull())[0]\n",
    "#x_12=np.where(df13['ANYALC'].isnull())[0]\n",
    "#x_13=np.where(df13['BINGEDAYS'].isnull())[0]\n",
    "x_6=np.where(df13['DRUGDAYS'].isnull())[0]\n",
    "x_7=np.where(df13['ALCDRUGS'].isnull())[0]\n",
    "#x_16=np.where(df13['DAYSCOCAINE'].isnull())[0]\n",
    "#x_17=np.where(df13['MARYJDAYS'].isnull())[0]\n",
    "\n",
    "#x_18=np.where(df13['METHDAYS'].isnull())[0]\n",
    "\n",
    "#x_19=np.where(df13['INJECT'].isnull())[0]\n",
    "x_8=np.where(df13['AGE'].isnull())[0]\n",
    "x_9=np.where(df13['TOBMONTH'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "instrumental-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_0=[]\n",
    "for i in x_0:\n",
    "        if(df12.iloc[i,0]==return_df13.iloc[i,0]):\n",
    "            true_0.append(i)\n",
    "true_1=[]\n",
    "for i in x_1:\n",
    "        if(df12.iloc[i,1]==return_df13.iloc[i,1]):\n",
    "            true_1.append(i)\n",
    "true_2=[]\n",
    "for i in x_2:\n",
    "        if(df12.iloc[i,2]==return_df13.iloc[i,2]):\n",
    "            true_2.append(i)\n",
    "true_3=[]\n",
    "for i in x_3:\n",
    "        if(df12.iloc[i,3]==return_df13.iloc[i,3]):\n",
    "            true_3.append(i)\n",
    "\n",
    "true_4=[]\n",
    "for i in x_4:\n",
    "        if(df12.iloc[i,4]==return_df13.iloc[i,4]):\n",
    "            true_4.append(i)\n",
    "   \n",
    "            \n",
    "true_5=[]\n",
    "for i in x_5:\n",
    "        if(df12.iloc[i,5]==return_df13.iloc[i,5]):\n",
    "            true_5.append(i)\n",
    "    \n",
    "true_6=[]\n",
    "for i in x_6:\n",
    "        if(df12.iloc[i,6]==return_df13.iloc[i,6]):\n",
    "            true_6.append(i)\n",
    "\n",
    "true_7=[]\n",
    "for i in x_7:\n",
    "        if(df12.iloc[i,7]==return_df13.iloc[i,7]):\n",
    "            true_7.append(i)\n",
    "true_8=[]\n",
    "for i in x_8:\n",
    "        if(df12.iloc[i,8]==return_df13.iloc[i,8]):\n",
    "            true_8.append(i)\n",
    "true_9=[]\n",
    "for i in x_9:\n",
    "        if(df12.iloc[i,9]==return_df13.iloc[i,9]):\n",
    "            true_9.append(i)\n",
    "# true_10=[]\n",
    "# for i in x_10:\n",
    "#         if(df12.iloc[i,10]==return_df13.iloc[i,10]):\n",
    "#             true_10.append(i)\n",
    "            \n",
    "# true_11=[]\n",
    "# for i in x_11:\n",
    "#         if(df12.iloc[i,11]==return_df13.iloc[i,11]):\n",
    "#             true_11.append(i)\n",
    "            \n",
    "            \n",
    "# true_12=[]\n",
    "# for i in x_12:\n",
    "#         if(df12.iloc[i,12]==return_df13.iloc[i,12]):\n",
    "#             true_12.append(i)\n",
    "            \n",
    "# true_13=[]\n",
    "# for i in x_13:\n",
    "#         if(df12.iloc[i,13]==return_df13.iloc[i,13]):\n",
    "#             true_13.append(i)\n",
    "            \n",
    "            \n",
    "# true_14=[]\n",
    "# for i in x_14:\n",
    "#         if(df12.iloc[i,14]==return_df13.iloc[i,14]):\n",
    "#             true_14.append(i)\n",
    "            \n",
    "# true_15=[]\n",
    "# for i in x_15:\n",
    "#         if(df12.iloc[i,15]==return_df13.iloc[i,15]):\n",
    "#             true_15.append(i)    \n",
    "            \n",
    "# true_16=[]\n",
    "# for i in x_16:\n",
    "#         if(df12.iloc[i,16]==return_df13.iloc[i,16]):\n",
    "#             true_16.append(i)\n",
    "            \n",
    "# true_17=[]\n",
    "# for i in x_17:\n",
    "#         if(df12.iloc[i,17]==return_df13.iloc[i,17]):\n",
    "#             true_17.append(i)\n",
    "            \n",
    "# true_18=[]\n",
    "# for i in x_18:\n",
    "#         if(df12.iloc[i,18]==return_df13.iloc[i,18]):\n",
    "#             true_18.append(i)      \n",
    "            \n",
    "            \n",
    "# true_19=[]\n",
    "# for i in x_19:\n",
    "#         if(df12.iloc[i,19]==return_df13.iloc[i,19]):\n",
    "#             true_19.append(i)   \n",
    "            \n",
    "            \n",
    "# true_20=[]\n",
    "# for i in x_20:\n",
    "#         if(df12.iloc[i,20]==return_df13.iloc[i,20]):\n",
    "#             true_20.append(i)   \n",
    "            \n",
    "            \n",
    "# true_21=[]\n",
    "# for i in x_21:\n",
    "#         if(df12.iloc[i,21]==return_df13.iloc[i,21]):\n",
    "#             true_21.append(i)   \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "southeast-telling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7157742402315485\n",
      "0.6033402922755742\n",
      "0.9046052631578947\n",
      "0.7841981132075472\n",
      "0.5903962973676598\n",
      "0.6771749014852986\n",
      "0.6100205098154117\n",
      "0.7973372781065089\n",
      "0.40759418570157224\n",
      "0.5899880810488677\n"
     ]
    }
   ],
   "source": [
    "## Accuracy in each column \n",
    "print(1-((len(x_0)-len(true_0))/len(x_0)))\n",
    "print(1-((len(x_1)-len(true_1))/len(x_1)))\n",
    "print(1-((len(x_2)-len(true_2))/len(x_2)))\n",
    "print(1-((len(x_3)-len(true_3))/len(x_3)))\n",
    "print(1-((len(x_4)-len(true_4))/len(x_4)))\n",
    "print(1-((len(x_5)-len(true_5))/len(x_5)))\n",
    "print(1-((len(x_6)-len(true_6))/len(x_6)))\n",
    "print(1-((len(x_7)-len(true_7))/len(x_7)))\n",
    "print(1-((len(x_8)-len(true_8))/len(x_8)))\n",
    "print(1-((len(x_9)-len(true_9))/len(x_9)))\n",
    "# print(1-((len(x_10)-len(true_10))/len(x_10)))\n",
    "# print(1-((len(x_11)-len(true_11))/len(x_11)))\n",
    "# print(1-((len(x_12)-len(true_12))/len(x_12)))\n",
    "# print(1-((len(x_13)-len(true_13))/len(x_13)))\n",
    "# print(1-((len(x_14)-len(true_14))/len(x_14)))\n",
    "# print(1-((len(x_15)-len(true_15))/len(x_15)))\n",
    "# print(1-((len(x_16)-len(true_16))/len(x_16)))\n",
    "# print(1-((len(x_17)-len(true_17))/len(x_17)))\n",
    "# print(1-((len(x_18)-len(true_18))/len(x_18)))\n",
    "# print(1-((len(x_19)-len(true_19))/len(x_19)))\n",
    "# print(1-((len(x_20)-len(true_20))/len(x_20)))\n",
    "# print(1-((len(x_21)-len(true_21))/len(x_21)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-might",
   "metadata": {},
   "source": [
    "### Iterative SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14 = data_0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = df14.copy()\n",
    "df15=df15.dropna()\n",
    "df15.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins= [0,21,30,45,60,100]\n",
    "labels = [1,2,3,4,5]\n",
    "df15['AGE'] = pd.cut(df15['AGE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['BINGEDAYS'] = pd.cut(df15['BINGEDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df9['DRUGDAYS'] = pd.cut(df15['DRUGDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['ALCDRUGS'] = pd.cut(df15['ALCDRUGS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['DAYSCOCAINE'] = pd.cut(df15['DAYSCOCAINE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['MARYJDAYS'] = pd.cut(df15['MARYJDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['ANYOPIATEDAYS'] = pd.cut(df15['ANYOPIATEDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['METHADONE'] = pd.cut(df15['METHADONE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['HALLUC'] = pd.cut(df15['HALLUC'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['METHDAYS'] = pd.cut(df15['METHDAYS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['OTHERDRUGS'] = pd.cut(df15['OTHERDRUGS'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins= [0,10,20,30,40]\n",
    "labels = [1,2,3,4]\n",
    "df15['ANYALC'] = pd.cut(df15['ANYALC'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "df15.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15['DAST'] = df15['DAST'].astype(float).astype(object)\n",
    "df15['SEX'] = df15['SEX'].astype(float).astype(object)\n",
    "df15['HISPANIC'] = df15['HISPANIC'].astype(float).astype(object)\n",
    "df15['RACE'] = df15['RACE'].astype(float).astype(object)\n",
    "df15['VET'] = df15['VET'].astype(float).astype(object)\n",
    "df15['ACTIVE'] = df15['ACTIVE'].astype(float).astype(object)\n",
    "df15['DEPLOY'] = df15['DEPLOY'].astype(float).astype(object)\n",
    "df15['AUDIT'] = df15['AUDIT'].astype(float).astype(object)\n",
    "df15['COSCREEN'] = df15['COSCREEN'].astype(float).astype(object)\n",
    "df15['RT'] = df15['RT'].astype(float).astype(object)\n",
    "df15['BI'] = df15['BI'].astype(float).astype(object)\n",
    "df15['BT'] = df15['BT'].astype(float).astype(object)\n",
    "df15['INJECT'] = df15['INJECT'].astype(float).astype(object)\n",
    "df15['TOBMONTH'] = df15['TOBMONTH'].astype(float).astype(object)\n",
    "###############################################################\n",
    "df15['ANYALC'] = df15['ANYALC'].astype(float).astype(object)\n",
    "df15['BINGEDAYS'] = df15['BINGEDAYS'].astype(float).astype(object)\n",
    "df15['DRUGDAYS'] = df15['DRUGDAYS'].astype(float).astype(object)\n",
    "\n",
    "df15['ALCDRUGS'] = df15['ALCDRUGS'].astype(float).astype(object)\n",
    "df15['DAYSCOCAINE'] = df15['DAYSCOCAINE'].astype(float).astype(object)\n",
    "df15['MARYJDAYS'] = df15['MARYJDAYS'].astype(float).astype(object)\n",
    "\n",
    "df15['ANYOPIATEDAYS'] = df15['ANYOPIATEDAYS'].astype(float).astype(object)\n",
    "df15['METHADONE'] = df15['METHADONE'].astype(float).astype(object)\n",
    "df15['HALLUC'] = df15['HALLUC'].astype(float).astype(object)\n",
    "\n",
    "df15['METHDAYS'] = df15['METHDAYS'].astype(float).astype(object)\n",
    "df15['OTHERDRUGS'] =df15['OTHERDRUGS'].astype(float).astype(object)\n",
    "df15['AGE'] = df15['AGE'].astype(float).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "df16 = df15.copy()\n",
    "replaced = collections.defaultdict(set)\n",
    "ix = [(row, col) for row in range(df16.shape[0]) for col in range(df16.shape[1])]\n",
    "random.shuffle(ix)\n",
    "to_replace = int(round(.1*len(ix)))\n",
    "for row, col in ix:\n",
    "    if len(replaced[row]) < df16.shape[1] - 1:\n",
    "        df16.iloc[row, col] = np.nan\n",
    "        to_replace -= 1\n",
    "        replaced[row].add(col)\n",
    "        if to_replace == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0=np.where(df16['DAST'].isnull())[0]\n",
    "x_1=np.where(df16['SEX'].isnull())[0]\n",
    "x_2=np.where(df16['HISPANIC'].isnull())[0]\n",
    "x_3=np.where(df16['RACE'].isnull())[0]\n",
    "x_4=np.where(df16['VET'].isnull())[0]\n",
    "x_5=np.where(df16['ACTIVE'].isnull())[0]\n",
    "x_6=np.where(df16['DEPLOY'].isnull())[0]\n",
    "x_7=np.where(df16['AUDIT'].isnull())[0]\n",
    "x_8=np.where(df16['COSCREEN'].isnull())[0]\n",
    "x_9=np.where(df16['BI'].isnull())[0]\n",
    "x_10=np.where(df16['BT'].isnull())[0]\n",
    "x_11=np.where(df16['RT'].isnull())[0]\n",
    "x_12=np.where(df16['ANYALC'].isnull())[0]\n",
    "x_13=np.where(df16['BINGEDAYS'].isnull())[0]\n",
    "x_14=np.where(df16['DRUGDAYS'].isnull())[0]\n",
    "x_15=np.where(df16['ALCDRUGS'].isnull())[0]\n",
    "x_16=np.where(df16['DAYSCOCAINE'].isnull())[0]\n",
    "x_17=np.where(df16['MARYJDAYS'].isnull())[0]\n",
    "x_18=np.where(df16['ANYOPIATEDAYS'].isnull())[0]\n",
    "x_19=np.where(df16['METHADONE'].isnull())[0]\n",
    "x_20=np.where(df16['HALLUC'].isnull())[0]\n",
    "x_21=np.where(df16['METHDAYS'].isnull())[0]\n",
    "x_22=np.where(df16['OTHERDRUGS'].isnull())[0]\n",
    "x_23=np.where(df16['INJECT'].isnull())[0]\n",
    "x_24=np.where(df16['AGE'].isnull())[0]\n",
    "x_25=np.where(df16['TOBMONTH'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate both packages to use \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute\n",
    "from fancyimpute import IterativeSVD\n",
    "encoder = OrdinalEncoder()\n",
    "imputer = IterativeSVD()\n",
    "#create a list of categorical columns to iterate over \n",
    "cat_cols =['DAST', 'SEX', 'HISPANIC', 'RACE','VET',  'ACTIVE', 'DEPLOY', 'AUDIT',\n",
    "       'COSCREEN', 'BI', 'BT', 'RT', 'ANYALC', 'BINGEDAYS', 'DRUGDAYS',\n",
    "       'ALCDRUGS', 'DAYSCOCAINE', 'MARYJDAYS', 'ANYOPIATEDAYS', 'METHADONE',\n",
    "       'HALLUC', 'METHDAYS', 'OTHERDRUGS', 'INJECT', 'AGE', 'TOBMONTH']\n",
    "\n",
    "def encode(data):\n",
    "    '''function to encode non-null data and replace it in the original data '''\n",
    "    #retain only non-null values \n",
    "    notnulls =np.array(data.dropna())\n",
    "    #reshape the data for encoding\n",
    "    impute_reshape = notnulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    print(impute_reshape.shape)\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Assign back encoded values to non-null values\n",
    "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "    return data\n",
    "\n",
    "#create a for loop to iterate through each column in the data \n",
    "for columns in cat_cols:\n",
    "    encode(df16[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data3 = pd.DataFrame(np.round(imputer.fit_transform(df16)),columns = df16.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15.iloc[:,0] = df15.iloc[:,0].astype(float).astype(int)\n",
    "df15.iloc[:,1] = df15.iloc[:,1].astype(float).astype(int)\n",
    "df15.iloc[:,2] = df15.iloc[:,2].astype(float).astype(int)\n",
    "df15.iloc[:,3] = df15.iloc[:,3].astype(float).astype(int)\n",
    "df15.iloc[:,4] = df15.iloc[:,4].astype(float).astype(int)\n",
    "df15.iloc[:,5] = df15.iloc[:,5].astype(float).astype(int)\n",
    "df15.iloc[:,6] = df15.iloc[:,6].astype(float).astype(int)\n",
    "df15.iloc[:,7]= df15.iloc[:,7].astype(float).astype(int)\n",
    "df15.iloc[:,8] = df15.iloc[:,8].astype(float).astype(int)\n",
    "df15.iloc[:,9] = df15.iloc[:,9].astype(float).astype(int)\n",
    "df15.iloc[:,10] = df15.iloc[:,10].astype(float).astype(int)\n",
    "df15.iloc[:,11]= df15.iloc[:,11].astype(float).astype(int)\n",
    "df15.iloc[:,12]= df15.iloc[:,12].astype(float).astype(int)\n",
    "df15.iloc[:,13] = df15.iloc[:,13].astype(float).astype(int)\n",
    "###############################################################\n",
    "df15.iloc[:,14] = df15.iloc[:,14].astype(float).astype(int)\n",
    "df15.iloc[:,15] = df15.iloc[:,15].astype(float).astype(int)\n",
    "df15.iloc[:,16] = df15.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "df15.iloc[:,17] = df15.iloc[:,17].astype(float).astype(int)\n",
    "df15.iloc[:,18]= df15.iloc[:,18].astype(float).astype(int)\n",
    "df15.iloc[:,19] = df15.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "df15.iloc[:,20] = df15.iloc[:,20].astype(float).astype(int)\n",
    "df15.iloc[:,21]= df15.iloc[:,21].astype(float).astype(int)\n",
    "df15.iloc[:,22]= df15.iloc[:,22].astype(float).astype(int)\n",
    "\n",
    "df15.iloc[:,23]= df15.iloc[:,23].astype(float).astype(int)\n",
    "df15.iloc[:,24]=df15.iloc[:,24].astype(float).astype(int)\n",
    "df15.iloc[:,25] = df15.iloc[:,25].astype(float).astype(int)\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "encode_data3.iloc[:,0] = encode_data3.iloc[:,0].astype(float).astype(int)\n",
    "encode_data3.iloc[:,1] = encode_data3.iloc[:,1].astype(float).astype(int)\n",
    "encode_data3.iloc[:,2] = encode_data3.iloc[:,2].astype(float).astype(int)\n",
    "encode_data3.iloc[:,3] = encode_data3.iloc[:,3].astype(float).astype(int)\n",
    "encode_data3.iloc[:,4] = encode_data3.iloc[:,4].astype(float).astype(int)\n",
    "encode_data3.iloc[:,5] = encode_data3.iloc[:,5].astype(float).astype(int)\n",
    "encode_data3.iloc[:,6] = encode_data3.iloc[:,6].astype(float).astype(int)\n",
    "encode_data3.iloc[:,7]= encode_data3.iloc[:,7].astype(float).astype(int)\n",
    "encode_data3.iloc[:,8] = encode_data3.iloc[:,8].astype(float).astype(int)\n",
    "encode_data3.iloc[:,9] = encode_data3.iloc[:,9].astype(float).astype(int)\n",
    "encode_data3.iloc[:,10] = encode_data3.iloc[:,10].astype(float).astype(int)\n",
    "encode_data3.iloc[:,11]= encode_data3.iloc[:,11].astype(float).astype(int)\n",
    "encode_data3.iloc[:,12]= encode_data3.iloc[:,12].astype(float).astype(int)\n",
    "encode_data3.iloc[:,13] = encode_data3.iloc[:,13].astype(float).astype(int)\n",
    "###############################################################\n",
    "encode_data3.iloc[:,14] = encode_data3.iloc[:,14].astype(float).astype(int)\n",
    "encode_data3.iloc[:,15] = encode_data3.iloc[:,15].astype(float).astype(int)\n",
    "encode_data3.iloc[:,16] = encode_data3.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "encode_data3.iloc[:,17] = encode_data3.iloc[:,17].astype(float).astype(int)\n",
    "encode_data3.iloc[:,18]= encode_data3.iloc[:,18].astype(float).astype(int)\n",
    "encode_data3.iloc[:,19] = encode_data3.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "encode_data3.iloc[:,20] = encode_data3.iloc[:,20].astype(float).astype(int)\n",
    "encode_data3.iloc[:,21]= encode_data3.iloc[:,21].astype(float).astype(int)\n",
    "encode_data3.iloc[:,22]= encode_data3.iloc[:,22].astype(float).astype(int)\n",
    "\n",
    "encode_data3.iloc[:,23]= encode_data3.iloc[:,23].astype(float).astype(int)\n",
    "encode_data3.iloc[:,24]=encode_data3.iloc[:,24].astype(float).astype(int)\n",
    "encode_data3.iloc[:,25] = encode_data3.iloc[:,25].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_0=[]\n",
    "for i in x_0:\n",
    "        if(df15.iloc[i,0]==encode_data3.iloc[i,0]):\n",
    "            true_0.append(i)\n",
    "true_1=[]\n",
    "for i in x_1:\n",
    "        if(df15.iloc[i,1]==encode_data3.iloc[i,1]):\n",
    "            true_1.append(i)\n",
    "true_2=[]\n",
    "for i in x_2:\n",
    "        if(df15.iloc[i,2]==encode_data3.iloc[i,2]):\n",
    "            true_2.append(i)\n",
    "true_3=[]\n",
    "for i in x_3:\n",
    "        if(df15.iloc[i,3]==encode_data3.iloc[i,3]):\n",
    "            true_3.append(i)\n",
    "\n",
    "true_4=[]\n",
    "for i in x_4:\n",
    "        if(df15.iloc[i,4]==encode_data3.iloc[i,4]):\n",
    "            true_4.append(i)\n",
    "   \n",
    "            \n",
    "true_5=[]\n",
    "for i in x_5:\n",
    "        if(df15.iloc[i,5]==encode_data3.iloc[i,5]):\n",
    "            true_5.append(i)\n",
    "    \n",
    "true_6=[]\n",
    "for i in x_6:\n",
    "        if(df15.iloc[i,6]==encode_data3.iloc[i,6]):\n",
    "            true_6.append(i)\n",
    "\n",
    "true_7=[]\n",
    "for i in x_7:\n",
    "        if(df15.iloc[i,7]==encode_data3.iloc[i,7]):\n",
    "            true_7.append(i)\n",
    "true_8=[]\n",
    "for i in x_8:\n",
    "        if(df15.iloc[i,8]==encode_data3.iloc[i,8]):\n",
    "            true_8.append(i)\n",
    "true_9=[]\n",
    "for i in x_9:\n",
    "        if(df15.iloc[i,9]==encode_data3.iloc[i,9]):\n",
    "            true_9.append(i)\n",
    "true_10=[]\n",
    "for i in x_10:\n",
    "        if(df15.iloc[i,10]==encode_data3.iloc[i,10]):\n",
    "            true_10.append(i)\n",
    "            \n",
    "true_11=[]\n",
    "for i in x_11:\n",
    "        if(df15.iloc[i,11]==encode_data3.iloc[i,11]):\n",
    "            true_11.append(i)\n",
    "            \n",
    "            \n",
    "true_12=[]\n",
    "for i in x_12:\n",
    "        if(df15.iloc[i,12]==encode_data3.iloc[i,12]):\n",
    "            true_12.append(i)\n",
    "            \n",
    "true_13=[]\n",
    "for i in x_13:\n",
    "        if(df15.iloc[i,13]==encode_data3.iloc[i,13]):\n",
    "            true_13.append(i)\n",
    "            \n",
    "            \n",
    "true_14=[]\n",
    "for i in x_14:\n",
    "        if(df15.iloc[i,14]==encode_data3.iloc[i,14]):\n",
    "            true_14.append(i)\n",
    "            \n",
    "true_15=[]\n",
    "for i in x_15:\n",
    "        if(df15.iloc[i,15]==encode_data3.iloc[i,15]):\n",
    "            true_15.append(i)    \n",
    "            \n",
    "true_16=[]\n",
    "for i in x_16:\n",
    "        if(df15.iloc[i,16]==encode_data3.iloc[i,16]):\n",
    "            true_16.append(i)\n",
    "            \n",
    "true_17=[]\n",
    "for i in x_17:\n",
    "        if(df15.iloc[i,17]==encode_data3.iloc[i,17]):\n",
    "            true_17.append(i)\n",
    "            \n",
    "true_18=[]\n",
    "for i in x_18:\n",
    "        if(df15.iloc[i,18]==encode_data3.iloc[i,18]):\n",
    "            true_18.append(i)      \n",
    "            \n",
    "            \n",
    "true_19=[]\n",
    "for i in x_19:\n",
    "        if(df15.iloc[i,19]==encode_data3.iloc[i,19]):\n",
    "            true_19.append(i)   \n",
    "            \n",
    "            \n",
    "true_20=[]\n",
    "for i in x_20:\n",
    "        if(df15.iloc[i,20]==encode_data3.iloc[i,20]):\n",
    "            true_20.append(i)   \n",
    "            \n",
    "            \n",
    "true_21=[]\n",
    "for i in x_21:\n",
    "        if(df15.iloc[i,21]==encode_data3.iloc[i,21]):\n",
    "            true_21.append(i)   \n",
    "            \n",
    "            \n",
    "true_22=[]\n",
    "for i in x_22:\n",
    "        if(df15.iloc[i,22]==encode_data3.iloc[i,22]):\n",
    "            true_22.append(i)   \n",
    "            \n",
    "            \n",
    "true_23=[]\n",
    "for i in x_23:\n",
    "        if(df15.iloc[i,23]==encode_data3.iloc[i,23]):\n",
    "            true_23.append(i)       \n",
    "            \n",
    "true_24=[]\n",
    "for i in x_24:\n",
    "        if(df15.iloc[i,24]==encode_data3.iloc[i,24]):\n",
    "            true_24.append(i)   \n",
    "            \n",
    "true_25=[]\n",
    "for i in x_25:\n",
    "        if(df15.iloc[i,25]==encode_data3.iloc[i,25]):\n",
    "            true_25.append(i)               \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy in each column \n",
    "print(1-((len(x_0)-len(true_0))/len(x_0)))\n",
    "print(1-((len(x_1)-len(true_1))/len(x_1)))\n",
    "print(1-((len(x_2)-len(true_2))/len(x_2)))\n",
    "print(1-((len(x_3)-len(true_3))/len(x_3)))\n",
    "print(1-((len(x_4)-len(true_4))/len(x_4)))\n",
    "print(1-((len(x_5)-len(true_5))/len(x_5)))\n",
    "print(1-((len(x_6)-len(true_6))/len(x_6)))\n",
    "print(1-((len(x_7)-len(true_7))/len(x_7)))\n",
    "print(1-((len(x_8)-len(true_8))/len(x_8)))\n",
    "print(1-((len(x_9)-len(true_9))/len(x_9)))\n",
    "print(1-((len(x_10)-len(true_10))/len(x_10)))\n",
    "print(1-((len(x_11)-len(true_11))/len(x_11)))\n",
    "print(1-((len(x_12)-len(true_12))/len(x_12)))\n",
    "print(1-((len(x_13)-len(true_13))/len(x_13)))\n",
    "print(1-((len(x_14)-len(true_14))/len(x_14)))\n",
    "print(1-((len(x_15)-len(true_15))/len(x_15)))\n",
    "print(1-((len(x_16)-len(true_16))/len(x_16)))\n",
    "print(1-((len(x_17)-len(true_17))/len(x_17)))\n",
    "print(1-((len(x_18)-len(true_18))/len(x_18)))\n",
    "print(1-((len(x_19)-len(true_19))/len(x_19)))\n",
    "print(1-((len(x_20)-len(true_20))/len(x_20)))\n",
    "print(1-((len(x_21)-len(true_21))/len(x_21)))\n",
    "print(1-((len(x_22)-len(true_22))/len(x_22)))\n",
    "print(1-((len(x_23)-len(true_23))/len(x_23)))\n",
    "print(1-((len(x_24)-len(true_24))/len(x_24)))\n",
    "print(1-((len(x_25)-len(true_25))/len(x_25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-adult",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-livestock",
   "metadata": {},
   "source": [
    "### Beta VAE Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16=pd.read_csv('/home/sameerahtalafha/new_project/new/tables/ALL1-original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16.iloc[:,0] = df16.iloc[:,0].astype(float).astype(int)\n",
    "df16.iloc[:,1] = df16.iloc[:,1].astype(float).astype(int)\n",
    "df16.iloc[:,2] = df16.iloc[:,2].astype(float).astype(int)\n",
    "df16.iloc[:,3] = df16.iloc[:,3].astype(float).astype(int)\n",
    "df16.iloc[:,4] = df16.iloc[:,4].astype(float).astype(int)\n",
    "df16.iloc[:,5] = df16.iloc[:,5].astype(float).astype(int)\n",
    "df16.iloc[:,6] = df16.iloc[:,6].astype(float).astype(int)\n",
    "df16.iloc[:,7]= df16.iloc[:,7].astype(float).astype(int)\n",
    "df16.iloc[:,8] = df16.iloc[:,8].astype(float).astype(int)\n",
    "df16.iloc[:,9] = df16.iloc[:,9].astype(float).astype(int)\n",
    "df16.iloc[:,10] = df16.iloc[:,10].astype(float).astype(int)\n",
    "df16.iloc[:,11]= df16.iloc[:,11].astype(float).astype(int)\n",
    "df16.iloc[:,12]= df16.iloc[:,12].astype(float).astype(int)\n",
    "df16.iloc[:,13] = df16.iloc[:,13].astype(float).astype(int)\n",
    "###############################################################\n",
    "df16.iloc[:,14] = df16.iloc[:,14].astype(float).astype(int)\n",
    "df16.iloc[:,15] = df16.iloc[:,15].astype(float).astype(int)\n",
    "df16.iloc[:,16] = df16.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "df16.iloc[:,17] = df16.iloc[:,17].astype(float).astype(int)\n",
    "df16.iloc[:,18]= df16.iloc[:,18].astype(float).astype(int)\n",
    "df16.iloc[:,19] = df16.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "df16.iloc[:,20] = df16.iloc[:,20].astype(float).astype(int)\n",
    "df16.iloc[:,21]= df16.iloc[:,21].astype(float).astype(int)\n",
    "\n",
    "df16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17=pd.read_csv('/home/sameerahtalafha/new_project/new/tables/ALL1-Missing.csv')\n",
    "df17.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0=np.where(df17['DAST'].isnull())[0]\n",
    "x_1=np.where(df17['SEX'].isnull())[0]\n",
    "x_2=np.where(df17['HISPANIC'].isnull())[0]\n",
    "x_3=np.where(df17['RACE'].isnull())[0]\n",
    "x_4=np.where(df17['VET'].isnull())[0]\n",
    "x_5=np.where(df17['ACTIVE'].isnull())[0]\n",
    "x_6=np.where(df17['DEPLOY'].isnull())[0]\n",
    "x_7=np.where(df17['AUDIT'].isnull())[0]\n",
    "x_8=np.where(df17['COSCREEN'].isnull())[0]\n",
    "x_9=np.where(df17['BI'].isnull())[0]\n",
    "x_10=np.where(df17['BT'].isnull())[0]\n",
    "x_11=np.where(df17['RT'].isnull())[0]\n",
    "x_12=np.where(df17['ANYALC'].isnull())[0]\n",
    "x_13=np.where(df17['BINGEDAYS'].isnull())[0]\n",
    "x_14=np.where(df17['DRUGDAYS'].isnull())[0]\n",
    "x_15=np.where(df17['ALCDRUGS'].isnull())[0]\n",
    "x_16=np.where(df17['DAYSCOCAINE'].isnull())[0]\n",
    "x_17=np.where(df17['MARYJDAYS'].isnull())[0]\n",
    "\n",
    "x_18=np.where(df17['METHDAYS'].isnull())[0]\n",
    "\n",
    "x_19=np.where(df17['INJECT'].isnull())[0]\n",
    "x_20=np.where(df17['AGE'].isnull())[0]\n",
    "x_21=np.where(df17['TOBMONTH'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18=pd.read_csv('/home/sameerahtalafha/new_project/Missing-Experments/Beta-VAE-Imputation/imputed_data_trial_1_VAE.csv')\n",
    "\n",
    "df18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAST=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,0]\n",
    "#     print(x)\n",
    "#     print(i)\n",
    "#     if(x[:1]=='+'):\n",
    "#         print(x)\n",
    "#         y=x[5:8]\n",
    "#         print(y)\n",
    "#     else:\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    DAST.append(float(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEX=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,1]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    SEX.append(float(y))\n",
    "SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "RACE=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,3]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    RACE.append(float(y))\n",
    "RACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "VET=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,4]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    VET.append(float(y))\n",
    "VET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIT=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,7]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    AUDIT.append(float(y))\n",
    "AUDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "COSCREEN=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,8]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    COSCREEN.append(float(y))\n",
    "COSCREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANYALC=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,12]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    ANYALC.append(float(y))\n",
    "ANYALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "COSCREEN=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,13]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    COSCREEN.append(float(y))\n",
    "COSCREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "COSCREEN=[]\n",
    "for i in range(16910):\n",
    "    x=df18.iloc[i,14]\n",
    "    y=x[:3]\n",
    "    \n",
    "        \n",
    "    COSCREEN.append(float(y))\n",
    "COSCREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18.iloc[:,0] = np.array(DAST).astype(float).astype(int)\n",
    "df18.iloc[:,1] = np.array(SEX).astype(float).astype(int)\n",
    "# df18.iloc[:,2] = df18.iloc[:,2].astype(float).astype(int)\n",
    "df18.iloc[:,3] = np.array(RACE).astype(float).astype(int)\n",
    "df18.iloc[:,4] = np.array(VET).astype(float).astype(int)\n",
    "# df18.iloc[:,5] = df18.iloc[:,5].astype(float).astype(int)\n",
    "# df18.iloc[:,6] = df18.iloc[:,6].astype(float).astype(int)\n",
    "df18.iloc[:,7]= np.array(AUDIT).astype(float).astype(int)\n",
    "df18.iloc[:,8] = np.array(COSCREEN).astype(float).astype(int)\n",
    "# df18.iloc[:,9] = df18.iloc[:,9].astype(float).astype(int)\n",
    "# df18.iloc[:,10] = df18.iloc[:,10].astype(float).astype(int)\n",
    "# df18.iloc[:,11]= df18.iloc[:,11].astype(float).astype(int)\n",
    "# df18.iloc[:,12]= np.array(ANYALC).astype(float).astype(int)\n",
    "# df18.iloc[:,13] = np.array(BINGEDAYS).astype(float).astype(int)\n",
    "# # ###############################################################\n",
    "# df18.iloc[:,14] = np.array(DRUGDAYS).astype(float).astype(int)\n",
    "# df18.iloc[:,15] = df18.iloc[:,15].astype(float).astype(int)\n",
    "# df18.iloc[:,16] = df18.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "# df18.iloc[:,17] = df18.iloc[:,17].astype(float).astype(int)\n",
    "# df18.iloc[:,18]= df18.iloc[:,18].astype(float).astype(int)\n",
    "# df18.iloc[:,19] = df18.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "# df18.iloc[:,20] = df18.iloc[:,20].astype(float).astype(int)\n",
    "# df18.iloc[:,21]= df18.iloc[:,21].astype(float).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_0=[]\n",
    "for i in x_0:\n",
    "        if(df16.iloc[i,0]==df18.iloc[i,0]):\n",
    "            true_0.append(i)\n",
    "true_1=[]\n",
    "for i in x_1:\n",
    "        if(df16.iloc[i,1]==df18.iloc[i,1]):\n",
    "            true_1.append(i)\n",
    "# true_2=[]\n",
    "# for i in x_2:\n",
    "#         if(df16.iloc[i,2]==df18.iloc[i,2]):\n",
    "            true_2.append(i)\n",
    "true_3=[]\n",
    "for i in x_3:\n",
    "        if(df16.iloc[i,3]==df18.iloc[i,3]):\n",
    "            true_3.append(i)\n",
    "\n",
    "# true_4=[]\n",
    "# for i in x_4:\n",
    "#         if(df16.iloc[i,4]==df18.iloc[i,4]):\n",
    "#             true_4.append(i)\n",
    "   \n",
    "            \n",
    "# true_5=[]\n",
    "# for i in x_5:\n",
    "#         if(df16.iloc[i,5]==df18.iloc[i,5]):\n",
    "#             true_5.append(i)\n",
    "    \n",
    "# true_6=[]\n",
    "# for i in x_6:\n",
    "#         if(df16.iloc[i,6]==df18.iloc[i,6]):\n",
    "#             true_6.append(i)\n",
    "\n",
    "true_7=[]\n",
    "for i in x_7:\n",
    "        if(df16.iloc[i,7]==df18.iloc[i,7]):\n",
    "            true_7.append(i)\n",
    "true_8=[]\n",
    "for i in x_8:\n",
    "        if(df16.iloc[i,8]==df18.iloc[i,8]):\n",
    "            true_8.append(i)\n",
    "# true_9=[]\n",
    "# for i in x_9:\n",
    "#         if(df16.iloc[i,9]==df18.iloc[i,9]):\n",
    "#             true_9.append(i)\n",
    "# true_10=[]\n",
    "# for i in x_10:\n",
    "#         if(df16.iloc[i,10]==df18.iloc[i,10]):\n",
    "#             true_10.append(i)\n",
    "            \n",
    "# true_11=[]\n",
    "# for i in x_11:\n",
    "#         if(df16.iloc[i,11]==df18.iloc[i,11]):\n",
    "#             true_11.append(i)\n",
    "            \n",
    "            \n",
    "# true_12=[]\n",
    "# for i in x_12:\n",
    "#         if(df16.iloc[i,12]==df18.iloc[i,12]):\n",
    "#             true_12.append(i)\n",
    "            \n",
    "# true_13=[]\n",
    "# for i in x_13:\n",
    "#         if(df16.iloc[i,13]==df18.iloc[i,13]):\n",
    "#             true_13.append(i)\n",
    "            \n",
    "            \n",
    "# true_14=[]\n",
    "# for i in x_14:\n",
    "#         if(df16.iloc[i,14]==df18.iloc[i,14]):\n",
    "#             true_14.append(i)\n",
    "            \n",
    "# true_15=[]\n",
    "# for i in x_15:\n",
    "#         if(df16.iloc[i,15]==df18.iloc[i,15]):\n",
    "#             true_15.append(i)    \n",
    "            \n",
    "# true_16=[]\n",
    "# for i in x_16:\n",
    "#         if(df16.iloc[i,16]==df18.iloc[i,16]):\n",
    "#             true_16.append(i)\n",
    "            \n",
    "# true_17=[]\n",
    "# for i in x_17:\n",
    "#         if(df16.iloc[i,17]==df18.iloc[i,17]):\n",
    "#             true_17.append(i)\n",
    "            \n",
    "# true_18=[]\n",
    "# for i in x_18:\n",
    "#         if(df16.iloc[i,18]==df18.iloc[i,18]):\n",
    "#             true_18.append(i)      \n",
    "            \n",
    "            \n",
    "# true_19=[]\n",
    "# for i in x_19:\n",
    "#         if(df16.iloc[i,19]==df18.iloc[i,19]):\n",
    "#             true_19.append(i)   \n",
    "            \n",
    "            \n",
    "# true_20=[]\n",
    "# for i in x_20:\n",
    "#         if(df16.iloc[i,20]==df18.iloc[i,20]):\n",
    "#             true_20.append(i)   \n",
    "            \n",
    "            \n",
    "# true_21=[]\n",
    "# for i in x_21:\n",
    "#         if(df16.iloc[i,21]==df18.iloc[i,21]):\n",
    "#             true_21.append(i)   \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy in each column \n",
    "print(1-((len(x_0)-len(true_0))/len(x_0)))\n",
    "print(1-((len(x_1)-len(true_1))/len(x_1)))\n",
    "# print(1-((len(x_2)-len(true_2))/len(x_2)))\n",
    "print(1-((len(x_3)-len(true_3))/len(x_3)))\n",
    "print(1-((len(x_4)-len(true_4))/len(x_4)))\n",
    "# print(1-((len(x_5)-len(true_5))/len(x_5)))\n",
    "# print(1-((len(x_6)-len(true_6))/len(x_6)))\n",
    "print(1-((len(x_7)-len(true_7))/len(x_7)))\n",
    "print(1-((len(x_8)-len(true_8))/len(x_8)))\n",
    "# print(1-((len(x_9)-len(true_9))/len(x_9)))\n",
    "# print(1-((len(x_10)-len(true_10))/len(x_10)))\n",
    "# print(1-((len(x_11)-len(true_11))/len(x_11)))\n",
    "# print(1-((len(x_12)-len(true_12))/len(x_12)))\n",
    "# print(1-((len(x_13)-len(true_13))/len(x_13)))\n",
    "# print(1-((len(x_14)-len(true_14))/len(x_14)))\n",
    "# print(1-((len(x_15)-len(true_15))/len(x_15)))\n",
    "# print(1-((len(x_16)-len(true_16))/len(x_16)))\n",
    "# print(1-((len(x_17)-len(true_17))/len(x_17)))\n",
    "# print(1-((len(x_18)-len(true_18))/len(x_18)))\n",
    "# print(1-((len(x_19)-len(true_19))/len(x_19)))\n",
    "# print(1-((len(x_20)-len(true_20))/len(x_20)))\n",
    "# print(1-((len(x_21)-len(true_21))/len(x_21)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-warrior",
   "metadata": {},
   "source": [
    "### Generative Adversarial Imputation Networks (GAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19=pd.read_csv('/home/sameerahtalafha/new_project/Missing-Experments/GAIN/data/original_data.csv')\n",
    "df19.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19.iloc[:,0] = df19.iloc[:,0].astype(float).astype(int)\n",
    "df19.iloc[:,1] = df19.iloc[:,1].astype(float).astype(int)\n",
    "df19.iloc[:,2] = df19.iloc[:,2].astype(float).astype(int)\n",
    "df19.iloc[:,3] = df19.iloc[:,3].astype(float).astype(int)\n",
    "df19.iloc[:,4] = df19.iloc[:,4].astype(float).astype(int)\n",
    "df19.iloc[:,5] = df19.iloc[:,5].astype(float).astype(int)\n",
    "df19.iloc[:,6] = df19.iloc[:,6].astype(float).astype(int)\n",
    "df19.iloc[:,7]= df19.iloc[:,7].astype(float).astype(int)\n",
    "df19.iloc[:,8] = df19.iloc[:,8].astype(float).astype(int)\n",
    "df19.iloc[:,9] = df19.iloc[:,9].astype(float).astype(int)\n",
    "df19.iloc[:,10] = df19.iloc[:,10].astype(float).astype(int)\n",
    "df19.iloc[:,11]= df19.iloc[:,11].astype(float).astype(int)\n",
    "df19.iloc[:,12]= df19.iloc[:,12].astype(float).astype(int)\n",
    "df19.iloc[:,13] = df19.iloc[:,13].astype(float).astype(int)\n",
    "###############################################################\n",
    "df19.iloc[:,14] = df19.iloc[:,14].astype(float).astype(int)\n",
    "df19.iloc[:,15] = df19.iloc[:,15].astype(float).astype(int)\n",
    "df19.iloc[:,16] = df19.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "df19.iloc[:,17] = df19.iloc[:,17].astype(float).astype(int)\n",
    "df19.iloc[:,18]= df19.iloc[:,18].astype(float).astype(int)\n",
    "df19.iloc[:,19] = df19.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "df19.iloc[:,20] = df19.iloc[:,20].astype(float).astype(int)\n",
    "df19.iloc[:,21]= df19.iloc[:,21].astype(float).astype(int)\n",
    "df19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20=pd.read_csv('/home/sameerahtalafha/new_project/Missing-Experments/GAIN/data/missing_data.csv')\n",
    "df20.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0=np.where(df20['DAST'].isnull())[0]\n",
    "x_1=np.where(df20['SEX'].isnull())[0]\n",
    "x_2=np.where(df20['HISPANIC'].isnull())[0]\n",
    "x_3=np.where(df20['RACE'].isnull())[0]\n",
    "x_4=np.where(df20['VET'].isnull())[0]\n",
    "x_5=np.where(df20['ACTIVE'].isnull())[0]\n",
    "x_6=np.where(df20['DEPLOY'].isnull())[0]\n",
    "x_7=np.where(df20['AUDIT'].isnull())[0]\n",
    "x_8=np.where(df20['COSCREEN'].isnull())[0]\n",
    "x_9=np.where(df20['BI'].isnull())[0]\n",
    "x_10=np.where(df20['BT'].isnull())[0]\n",
    "x_11=np.where(df20['RT'].isnull())[0]\n",
    "x_12=np.where(df20['ANYALC'].isnull())[0]\n",
    "x_13=np.where(df20['BINGEDAYS'].isnull())[0]\n",
    "x_14=np.where(df20['DRUGDAYS'].isnull())[0]\n",
    "x_15=np.where(df20['ALCDRUGS'].isnull())[0]\n",
    "x_16=np.where(df20['DAYSCOCAINE'].isnull())[0]\n",
    "x_17=np.where(df20['MARYJDAYS'].isnull())[0]\n",
    "x_18=np.where(df20['METHDAYS'].isnull())[0]\n",
    "x_19=np.where(df20['INJECT'].isnull())[0]\n",
    "x_20=np.where(df20['AGE'].isnull())[0]\n",
    "x_21=np.where(df20['TOBMONTH'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21=pd.read_csv('/home/sameerahtalafha/new_project/Missing-Experments/GAIN/data/imputed_data.csv')\n",
    "df21.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21.iloc[:,0] = df21.iloc[:,0].astype(float).astype(int)\n",
    "df21.iloc[:,1] = df21.iloc[:,1].astype(float).astype(int)\n",
    "df21.iloc[:,2] = df21.iloc[:,2].astype(float).astype(int)\n",
    "df21.iloc[:,3] = df21.iloc[:,3].astype(float).astype(int)\n",
    "df21.iloc[:,4] = df21.iloc[:,4].astype(float).astype(int)\n",
    "df21.iloc[:,5] = df21.iloc[:,5].astype(float).astype(int)\n",
    "df21.iloc[:,6] = df21.iloc[:,6].astype(float).astype(int)\n",
    "df21.iloc[:,7]= df21.iloc[:,7].astype(float).astype(int)\n",
    "df21.iloc[:,8] = df21.iloc[:,8].astype(float).astype(int)\n",
    "df21.iloc[:,9] = df21.iloc[:,9].astype(float).astype(int)\n",
    "df21.iloc[:,10] = df21.iloc[:,10].astype(float).astype(int)\n",
    "df21.iloc[:,11]= df21.iloc[:,11].astype(float).astype(int)\n",
    "df21.iloc[:,12]= df21.iloc[:,12].astype(float).astype(int)\n",
    "df21.iloc[:,13] = df21.iloc[:,13].astype(float).astype(int)\n",
    "###############################################################\n",
    "df21.iloc[:,14] = df21.iloc[:,14].astype(float).astype(int)\n",
    "# df21.iloc[:,15] = df21.iloc[:,15].astype(float).astype(int)\n",
    "# df21.iloc[:,16] = df21.iloc[:,16].astype(float).astype(int)\n",
    "\n",
    "# df21.iloc[:,17] = df21.iloc[:,17].astype(float).astype(int)\n",
    "# df21.iloc[:,18]= df21.iloc[:,18].astype(float).astype(int)\n",
    "# df21.iloc[:,19] = df21.iloc[:,19].astype(float).astype(int)\n",
    "\n",
    "# df21.iloc[:,20] = df21.iloc[:,20].astype(float).astype(int)\n",
    "# df21.iloc[:,21]= df21.iloc[:,21].astype(float).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_0=[]\n",
    "for i in x_0:\n",
    "        if(df19.iloc[i,0]==df21.iloc[i,0]):\n",
    "            true_0.append(i)\n",
    "true_1=[]\n",
    "for i in x_1:\n",
    "        if(df19.iloc[i,1]==df21.iloc[i,1]):\n",
    "            true_1.append(i)\n",
    "true_2=[]\n",
    "for i in x_2:\n",
    "        if(df19.iloc[i,2]==df21.iloc[i,2]):\n",
    "            true_2.append(i)\n",
    "true_3=[]\n",
    "for i in x_3:\n",
    "        if(df19.iloc[i,3]==df21.iloc[i,3]):\n",
    "            true_3.append(i)\n",
    "\n",
    "true_4=[]\n",
    "for i in x_4:\n",
    "        if(df19.iloc[i,4]==df21.iloc[i,4]):\n",
    "            true_4.append(i)\n",
    "   \n",
    "            \n",
    "true_5=[]\n",
    "for i in x_5:\n",
    "        if(df19.iloc[i,5]==df21.iloc[i,5]):\n",
    "            true_5.append(i)\n",
    "    \n",
    "true_6=[]\n",
    "for i in x_6:\n",
    "        if(df19.iloc[i,6]==df21.iloc[i,6]):\n",
    "            true_6.append(i)\n",
    "\n",
    "true_7=[]\n",
    "for i in x_7:\n",
    "        if(df19.iloc[i,7]==df21.iloc[i,7]):\n",
    "            true_7.append(i)\n",
    "true_8=[]\n",
    "for i in x_8:\n",
    "        if(df19.iloc[i,8]==df21.iloc[i,8]):\n",
    "            true_8.append(i)\n",
    "true_9=[]\n",
    "for i in x_9:\n",
    "        if(df19.iloc[i,9]==df21.iloc[i,9]):\n",
    "            true_9.append(i)\n",
    "true_10=[]\n",
    "for i in x_10:\n",
    "        if(df19.iloc[i,10]==df21.iloc[i,10]):\n",
    "            true_10.append(i)\n",
    "            \n",
    "true_11=[]\n",
    "for i in x_11:\n",
    "        if(df19.iloc[i,11]==df21.iloc[i,11]):\n",
    "            true_11.append(i)\n",
    "            \n",
    "            \n",
    "true_12=[]\n",
    "for i in x_12:\n",
    "        if(df19.iloc[i,12]==df21.iloc[i,12]):\n",
    "            true_12.append(i)\n",
    "            \n",
    "true_13=[]\n",
    "for i in x_13:\n",
    "        if(df19.iloc[i,13]==df21.iloc[i,13]):\n",
    "            true_13.append(i)\n",
    "            \n",
    "            \n",
    "true_14=[]\n",
    "for i in x_14:\n",
    "        if(df19.iloc[i,14]==df21.iloc[i,14]):\n",
    "            true_14.append(i)\n",
    "            \n",
    "true_15=[]\n",
    "for i in x_15:\n",
    "        if(df19.iloc[i,15]==df21.iloc[i,15]):\n",
    "            true_15.append(i)    \n",
    "            \n",
    "# true_16=[]\n",
    "# for i in x_16:\n",
    "#         if(df19.iloc[i,16]==df21.iloc[i,16]):\n",
    "#             true_16.append(i)\n",
    "            \n",
    "# true_17=[]\n",
    "# for i in x_17:\n",
    "#         if(df19.iloc[i,17]==df21.iloc[i,17]):\n",
    "#             true_17.append(i)\n",
    "            \n",
    "# true_18=[]\n",
    "# for i in x_18:\n",
    "#         if(df19.iloc[i,18]==df21.iloc[i,18]):\n",
    "#             true_18.append(i)      \n",
    "            \n",
    "            \n",
    "# true_19=[]\n",
    "# for i in x_19:\n",
    "#         if(df19.iloc[i,19]==df21.iloc[i,19]):\n",
    "#             true_19.append(i)   \n",
    "            \n",
    "            \n",
    "# true_20=[]\n",
    "# for i in x_20:\n",
    "#         if(df19.iloc[i,20]==df21.iloc[i,20]):\n",
    "#             true_20.append(i)   \n",
    "            \n",
    "            \n",
    "# true_21=[]\n",
    "# for i in x_21:\n",
    "#         if(df19.iloc[i,21]==df21.iloc[i,21]):\n",
    "#             true_21.append(i)   \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy in each column \n",
    "print(1-((len(x_0)-len(true_0))/len(x_0)))\n",
    "print(1-((len(x_1)-len(true_1))/len(x_1)))\n",
    "print(1-((len(x_2)-len(true_2))/len(x_2)))\n",
    "print(1-((len(x_3)-len(true_3))/len(x_3)))\n",
    "print(1-((len(x_4)-len(true_4))/len(x_4)))\n",
    "print(1-((len(x_5)-len(true_5))/len(x_5)))\n",
    "print(1-((len(x_6)-len(true_6))/len(x_6)))\n",
    "print(1-((len(x_7)-len(true_7))/len(x_7)))\n",
    "print(1-((len(x_8)-len(true_8))/len(x_8)))\n",
    "print(1-((len(x_9)-len(true_9))/len(x_9)))\n",
    "print(1-((len(x_10)-len(true_10))/len(x_10)))\n",
    "print(1-((len(x_11)-len(true_11))/len(x_11)))\n",
    "print(1-((len(x_12)-len(true_12))/len(x_12)))\n",
    "print(1-((len(x_13)-len(true_13))/len(x_13)))\n",
    "print(1-((len(x_14)-len(true_14))/len(x_14)))\n",
    "print(1-((len(x_15)-len(true_15))/len(x_15)))\n",
    "# print(1-((len(x_16)-len(true_16))/len(x_16)))\n",
    "# print(1-((len(x_17)-len(true_17))/len(x_17)))\n",
    "# print(1-((len(x_18)-len(true_18))/len(x_18)))\n",
    "# print(1-((len(x_19)-len(true_19))/len(x_19)))\n",
    "# print(1-((len(x_20)-len(true_20))/len(x_20)))\n",
    "# print(1-((len(x_21)-len(true_21))/len(x_21)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-trade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_0=np.where(df20['AGE'].isnull())[0]\n",
    "true_0=[]\n",
    "for i in x_0:\n",
    "    if(df19.iloc[i,0]==df21.iloc[i,0]):\n",
    "        true_0.append(i)\n",
    "len(true_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0=np.where(df20['AGE'].isnull())[0]\n",
    "len(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-mercury",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "473/2836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-chosen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
